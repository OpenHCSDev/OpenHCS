\section{Discussion}\label{discussion}

\subsection{Methodology and Disclosure}\label{methodology-disclosure}

\textbf{Role of LLMs in this work.} This paper was developed through
human-AI collaboration. The author provided the core intuitions,
conjectures, and architectural insights; large language models (Claude,
GPT-4) served as implementation partners---drafting proofs, suggesting
formalizations, and generating code. The Lean 4 proofs were iteratively
refined through this collaboration: the author specified what should be
proved, the LLM proposed proof strategies, and the Lean compiler served
as the ultimate arbiter of correctness.

This methodology aligns with the paper's thesis: the Lean proofs are
\emph{costly signals} (per the companion paper on credibility) because
they require computational verification regardless of how they were
generated. A proof that compiles is correct; the generation method is
epistemically irrelevant to validity. The LLM accelerated exploration
and drafting; the theorems stand or fall on their machine-checked
proofs alone.

\textbf{What the author contributed:} The $(B, S)$ decomposition,
the strict dominance conjecture, the provenance impossibility claim,
the connection to complexity bounds, the case study selection, and the
architectural framing.

\textbf{What LLMs contributed:} LaTeX drafting, Lean tactic suggestions,
literature search assistance, prose refinement, and exploration of proof
strategies.

\textbf{Why this disclosure matters:} Academic norms around authorship
and originality are evolving. We believe transparency about methodology
strengthens rather than weakens the work. The proofs are machine-checked;
the claims are falsifiable; the contribution is the insight, not the
typing.

\subsection{Limitations}\label{limitations}

Our theorems establish necessary conditions for provenance-tracking
systems, but several limitations warrant explicit acknowledgment:

\textbf{Diamond inheritance.} Our theorems assume well-formed MRO
produced by C3 linearization. Pathological diamond inheritance patterns
can break C3 entirely---Python raises \texttt{TypeError} when
linearization fails. Such cases require manual resolution or interface
redesign. Our complexity bounds apply only when C3 succeeds.

\textbf{Runtime overhead.} Provenance tracking stores
\texttt{(value,\ scope\_id,\ source\_type)} tuples for each resolved
field. This introduces memory overhead proportional to the number of
lazy fields. In OpenHCS, this overhead is negligible (\textless{} 1\% of
total memory usage), but systems with millions of configuration objects
may need to consider this cost.

\textbf{Scope: systems where \(B \neq \emptyset\).} Simple scripts where
the entire program fits in working memory may not require provenance
tracking. But provenance is just one of four capabilities (Theorem
2.17). Even without provenance requirements, $\{B,S\}$ typing dominates
because it provides identity, enumeration, and conflict resolution at no
additional cost. Our theorems apply universally when
\(B \neq \emptyset\).

\textbf{Remark:} Traditional term: nominal typing.

\textbf{Python as canonical model.} The formalization uses Python's
\texttt{type(name,\ bases,\ namespace)} because it is the clearest
expression of the two-axis model. This is a strength, not a
limitation: Python's explicit constructor exposes what other languages
obscure with syntax. Table 2.2 demonstrates that 8 major languages
(Java, C\#, Rust, TypeScript, Kotlin, Swift, Scala, C++) are isomorphic
to this model. Theorem 3.50 proves universality.

\textbf{Metaclass complexity.} The \texttt{@global\_pipeline\_config}
chain (Case Study 7) requires understanding five metaprogramming stages:
decorator invocation, metaclass \texttt{\_\_prepare\_\_}, descriptor
\texttt{\_\_set\_name\_\_}, field injection, and type registration. This
complexity is manageable in OpenHCS because it's encapsulated in a
single decorator, but unconstrained metaclass composition can lead to
maintenance challenges.

\textbf{Lean proofs assume well-formedness.} Our Lean 4 verification
includes \texttt{Registry.wellFormed} and MRO monotonicity as axioms
rather than derived properties. We prove theorems \emph{given} these
axioms, but do not prove the axioms themselves from more primitive
foundations. This is standard practice in mechanized verification (e.g.,
CompCert assumes well-typed input), but limits the scope of our
machine-checked guarantees.

\textbf{Validation scope.} The formal results (Theorems 3.5,
3.13, Corollary 6.3) are proven universally for any system where
\(B \neq \emptyset\). These proofs establish \emph{what is impossible}:
provenance cannot be computed without the bases axis
(information-theoretically impossible, not merely difficult). The
case studies (Section 5) demonstrate these theorems in a production
codebase. The \emph{direction} of the claims (that capability gaps
translate to error reduction) follows from the formalism: if provenance is
impossible without $\{B,S\}$ typing (Corollary 6.3), and provenance is
required (PC = 1), then errors \emph{must} occur under $\{S\}$-only incoherent typing. The
\emph{magnitude} of the effect is codebase-specific; the
\emph{existence} of the effect is not. We distinguish:

\textbf{Remark:} Traditional terms: nominal typing vs duck typing.

\begin{itemize}
\tightlist
\item
  \textbf{Universal (proven):} Capability gap exists, provenance is
  impossible under $\{S\}$-only typing, $\{B,S\}$ typing strictly dominates.
\item
  \textbf{Singular (observed):} 47 \texttt{hasattr()} calls eliminated,
  centralized error detection via ABC contracts.
\end{itemize}

\textbf{Remark:} In type system terminology, "$\{S\}$-only typing" and "$\{B,S\}$ typing" correspond to duck/structural typing and nominal typing respectively.

We call for replication studies on other codebases to measure the
magnitude of the effect across different architectural patterns. The
formal results predict that \emph{some} positive effect will be
observed in any \(B \neq \emptyset\) system requiring provenance; the
specific multipliers are empirical questions.

\textbf{OpenHCS is also wrong.} The universal principle (Section~\ref{the-classification-problem}) applies to OpenHCS itself. OpenHCS currently fixes the axis set \(A = \{B, S, H\}\) (Bases, Shape, Hierarchy). By the Fixed Axis Incompleteness theorem, domains requiring axes outside this set (temporal versioning, provenance chains, security contexts, resource affinity) cannot be served.

OpenHCS is \emph{less wrong} than $\{S\}$-only typing or $\{B,S\}$-only typing because it includes more axes (\(A = \{B, S, H\}\)). But ``less wrong'' is not ``correct.'' The theorems predict that as the space of domains grows, OpenHCS will encounter impossibility walls:
\[
\lim_{|\text{Domains}| \to \infty} |\{D : \neg\text{complete}(\{B, S, H\}, D)\}| = \infty
\]

This is not speculation. It follows from \texttt{fixed\_axis\_incompleteness}: for each axis outside \(\{B, S, H\}\), there exists a domain OpenHCS cannot serve. Since the space of possible axes is unbounded, so is the failure count.

\textbf{Remark (Epistemic Strengthening).} The incompleteness result does not depend on the axis space being \emph{ontologically} infinite. Even if the space of possible axes were finite, no designer \emph{knows} the complete set. The relevant constraint is epistemic: you cannot guarantee your fixed axis set is sufficient without proving completeness over all possible domains. Since no such proof exists for any fixed set, the designer's epistemic position is identical whether the axis space is infinite or merely unknown. This parallels G\"{o}del's incompleteness (you cannot prove consistency from within) and Turing's halting problem (you cannot decide in advance which programs halt). The limitation is on what you can \emph{know}, not merely on what \emph{is}.

\textbf{The path forward.} Future versions of OpenHCS should parameterize over axis sets rather than hardcoding \(\{B, S, H\}\). The architecture should be:
\begin{verbatim}
OpenHCS : AxisSet -> ConfigurationSystem
\end{verbatim}
instantiated with \(\{B, S, H\}\) for current use cases, but extensible to new axes without modification. This is the subject of ongoing work (see Section~\ref{future-work}).

\paragraph{8.1 Axes as Query Dimensions}\label{axes-as-query-dimensions}

The paper's central claim---that axes are mandatory for specific capabilities---follows from a more primitive observation: \emph{axes are query dimensions}. Every capability is operationally defined as answering a specific query, and each query requires traversal along specific axes.

\textbf{Definition 8.1 (Query Parameterization).} Let \(T\) denote type-level access to an object. Query complexity is parameterized by the axis set \(A\) required for resolution:
\begin{itemize}
\item \(T\): Base object access (no axes required)
\item \(T(S)\): Attribute lookup---requires shape axis \(S\)
\item \(T(S,B)\): Attribute at inheritance level---requires shape \(S\) and bases \(B\)
\item \(T(S,B,H)\): Attribute at inheritance level within containment tree---requires \(S\), \(B\), and hierarchy \(H\)
\item \(T(S,B,H,\tau)\): Temporally-versioned attribute at inheritance level in containment tree---adds temporal axis \(\tau\)
\end{itemize}

\textbf{Theorem 8.1a (Query-Axis Necessity).} A query of form \(T(A)\) cannot be computed in a type system with axis set \(A' \subsetneq A\). The query is information-theoretically impossible, not merely inefficient.

\emph{Proof.} By construction, \(T(A)\) requires traversal along dimension \(a \in A \setminus A'\). Since \(a\) is absent from the type system, no structural path exists to resolve the query. Manual value-level encoding (e.g., \texttt{\_\_source\_\_} attributes) degrades the query to runtime inspection (\(\Omega(n)\) error localization) but does not eliminate the axis---it encodes it in imperative state. \qed

\textbf{Corollary 8.1b (Provenance as \(T(S,B)\) Query).} ``Which type provided this value?'' is a \(T(S,B)\) query: given field \(f \in S\) (shape), determine \(C \in \text{MRO}\) (bases) where \(f\) was defined. Duck typing (\(\{S\}\)-only) cannot answer this query (Corollary 6.3); nominal typing (\(\{B,S\}\)) can.

\textbf{Example 8.1 (Hierarchy Query).} OpenHCS's dual-axis resolver answers: ``Given pipeline node \(n\) and field \(f\), what is \(f\)'s value in \(n\)'s scope?'' This is a \(T(S,H)\) query (shape + hierarchy). Python provides \(\{B,S\}\) natively; OpenHCS implements \(H\) manually via \texttt{ContextNode} graph traversal.

\textbf{Theorem 8.1c (Manual Axis Complexity Superlinearity).} Let \(A_{\text{native}}\) be a language's native axes and \(A_{\text{req}}\) be domain-required axes. For \(k = |A_{\text{req}} \setminus A_{\text{native}}|\) manually-implemented axes, implementation complexity grows as \(\Omega(k^2)\) due to synergistic interaction, not \(O(k)\).

\emph{Proof sketch.} Each manually-encoded axis \(a_i\) requires: (1) storage semantics (where axis data lives), (2) query interface (how to traverse the dimension), (3) consistency invariants (what axis combinations are valid). For \(k\) axes, pairwise interactions number \(\binom{k}{2} = O(k^2)\). Examples of interactions:
\begin{itemize}
\item \emph{Hierarchy \(\times\) Bases:} When node \(n\) inherits configuration \(C\), must hierarchy position propagate through MRO, or does MRO reset at each tree level?
\item \emph{Temporal \(\times\) Hierarchy:} When pipeline structure changes over time, do version timestamps apply per-node or per-tree?
\item \emph{Security \(\times\) Bases:} Do permission scopes inherit via MRO, or are they hierarchy-local?
\end{itemize}

Each interaction creates \(O(1)\) design decisions, but incorrect choices lead to \emph{irrecoverable architectural states}: local minima where refactoring requires rewriting all \(k\) axes simultaneously. This is the synergistic complexity penalty.

Native axes avoid this: the language runtime enforces interaction semantics (e.g., Python's MRO + descriptor protocol defines how \(B \times S\) interact). Manual implementations must specify \emph{all} interactions explicitly, and inconsistency across axes compounds error rates super-linearly. \qed

\textbf{Corollary 8.1d (Fixed-Axis Penalty Function).} For a type system with native axes \(A_n\) and domain requiring \(A_d\), the penalty for \(|A_d \setminus A_n| = k\) missing axes is:
\[
\text{Penalty}(k) = O(k) \text{ (storage)} + \Omega(k^2) \text{ (interactions)} + \text{LocalMinima}(k)
\]
where \(\text{LocalMinima}(k)\) represents irrecoverable architectural debt from inconsistent interaction choices.

\textbf{Remark.} This formalizes why ``just implement it manually'' fails at scale. One missing axis (\(k=1\)) is manageable. Two axes (\(k=2\)) create \(\binom{2}{2}=1\) interaction. Three axes (\(k=3\)) create \(\binom{3}{2}=3\) interactions. At \(k=5\) (e.g., temporal, security, provenance, resource affinity, versioning), \(\binom{5}{2}=10\) interactions must be specified manually, and the probability of reaching a local minimum approaches 1.

\subsubsection{Connection to Degrees of Freedom}\label{sec:dof-connection}

The super-linear complexity \(\Omega(k^2)\) is not merely implementation cost---it directly corresponds to \emph{degrees of freedom} (DOF) in the system architecture, as formalized in the companion paper on Single Source of Truth~\cite{paper2_ssot}.

\textbf{Coherence and Structural Facts.} Paper 2 defines \emph{coherence} as: all encoding locations agree on the same value for a fact. A \emph{structural fact} is a fact about program structure (e.g., ``Type \(T\) has method \(m\)'' or ``These are all types implementing interface \(I\)''). When DOF \(> 1\), multiple independent locations can hold different values for the same structural fact, creating \emph{incoherence}: the system cannot determine which value is ``true.'' For manual axis implementation, each axis and each axis interaction is an independent encoding location, yielding DOF \(= \Omega(k^2)\). This characterizes a \emph{specific property}---coherence for structural facts---not general language quality. Languages make different trade-offs: static languages (Rust, Java, Go) choose compile-time safety over runtime introspection, accepting DOF \(> 1\) as a consequence; dynamic languages (Python, CLOS, Smalltalk) enable DOF \(= 1\) at the cost of performance and static guarantees.

\textbf{Theorem 8.2 (DOF-Complexity Correspondence).} For \(k\) manually-implemented axes, the architectural degrees of freedom satisfy:
\[
\text{DOF}_{\text{total}} = k + \Omega(k^2)
\]
where \(k\) represents storage DOF (one independent location per axis) and \(\Omega(k^2)\) represents interaction DOF (independent decisions for each axis pair).

\begin{proof}
By Definition 2.6 of~\cite{paper2_ssot}, DOF counts \emph{independent encoding locations} for architectural facts. For \(k\) manually-implemented axes:

\textbf{Storage DOF = \(k\):} Each axis \(a_i\) requires independent choice of:
\begin{itemize}
\item Where axis data is stored (object attribute, separate mapping, context variable)
\item Data structure representation (dict, tree, graph)
\item Mutability semantics (immutable, copy-on-write, in-place)
\end{itemize}

These \(k\) choices are \emph{independent} in the sense that no language constraint forces agreement. Different axes can use different storage strategies, and the system remains type-correct (though architecturally inconsistent).

\textbf{Interaction DOF = \(\Omega(k^2)\):} For each axis pair \((a_i, a_j)\), independent choices include:
\begin{itemize}
\item \emph{Traversal order:} Does query \(T(a_i, a_j)\) traverse \(a_i\) first or \(a_j\) first?
\item \emph{Composition semantics:} Are values at \((a_i, a_j)\) derived by combining separate \(T(a_i)\) and \(T(a_j)\) queries, or is the combination primitive?
\item \emph{Invalidation propagation:} When \(a_i\) changes, must \(a_j\)-indexed caches be invalidated?
\item \emph{Consistency invariants:} Can \(a_i\) and \(a_j\) hold contradictory information, or are they constrained to agree?
\end{itemize}

The number of axis pairs is \(\binom{k}{2} = \frac{k(k-1)}{2} = \Omega(k^2)\). Each pair introduces \(O(1)\) independent decisions. Therefore, interaction DOF \(= O(k^2)\).

Total: \(\text{DOF}_{\text{total}} = k + O(k^2) = \Omega(k^2)\). \qed
\end{proof}

\textbf{Corollary 8.2a (Modification Complexity Bound).} By Theorem 6.2 of~\cite{paper2_ssot} (Non-SSOT Lower Bound), modification complexity for architectural changes satisfies:
\[
M_{\text{effective}} = \Omega(\text{DOF}) = \Omega(k^2)
\]

\begin{proof}
Theorem 6.2 of~\cite{paper2_ssot} establishes that for DOF \(= n\) independent encoding locations, effective modification complexity \(M_{\text{effective}} = \Omega(n)\). By Theorem 8.2, \(\text{DOF} = \Omega(k^2)\) for \(k\) manually-implemented axes. Substituting: \(M_{\text{effective}} = \Omega(k^2)\). \qed
\end{proof}

\textbf{Example 8.2 (OpenHCS Hierarchy Axis).} OpenHCS's dual-axis configuration framework implements hierarchy \(H\) manually (Python provides \(B, S\) natively). With \(k=1\) manual axis:
\begin{itemize}
\item \textbf{Storage DOF = 1:} Hierarchy stored in \texttt{ContextNode} graph (\textasciitilde 500 LOC)
\item \textbf{Interaction DOF:} 
  \begin{itemize}
  \item \(H \times B\): Does MRO traversal reset at each hierarchy level, or propagate through tree? (Decision: propagate)
  \item \(H \times S\): Are field accesses scoped per-node or per-subtree? (Decision: per-node with fallback)
  \end{itemize}
\item \textbf{Total:} \(\text{DOF} = 1 + 2 = 3\) independent architectural decisions
\end{itemize}

For \(k=2\) axes (e.g., adding temporal versioning \(\tau\)):
\begin{itemize}
\item \textbf{Storage DOF = 2:} Hierarchy + temporal storage
\item \textbf{Interaction DOF:} \(\binom{2}{2} + \binom{3}{2} = 1 + 3 = 4\) interactions (\(H \times \tau\), plus 3 existing)
\item \textbf{Total:} \(\text{DOF} = 2 + 4 = 6\) (doubled from \(k=1\))
\end{itemize}

This quadratic growth explains why OpenHCS stopped at \(H\)---adding \(\tau\) would require \(\Omega(k^2)\) additional design decisions, each a potential inconsistency.

\textbf{Remark.} The DOF framework explains the ``local minima'' phenomenon: when \(k\) axes make inconsistent interaction choices, refactoring requires changing \(\Omega(k^2)\) independent locations simultaneously. By Theorem 6.3 of~\cite{paper2_ssot} (Unbounded Gap), this creates modification complexity that grows without bound as the codebase scales. Native axes avoid this: the language enforces interaction semantics (e.g., Python's descriptor protocol defines \(B \times S\) interaction), keeping DOF = 1 per axis.

\paragraph{8.1.1 Axiom Methodology}\label{axiom-methodology}

\textbf{Theorem 8.1a (Axiom Scope).} The axioms
\texttt{Registry.wellFormed} and MRO monotonicity are \emph{descriptive}
of well-formed programs, not \emph{restrictive} of the proof's scope.
Programs violating these axioms are rejected by the language runtime
before execution.

\emph{Proof.} We enumerate each axiom and its enforcement:

\small
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1522}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3913}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4565}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Axiom
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
What It Requires
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Language Enforcement
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{Registry.wellFormed} & No duplicate ABC registrations, no cycles
& \texttt{ABCMeta.register()} raises on duplicates; Python rejects
cyclic inheritance \\
MRO monotonicity & If A \textless: B, A precedes B in MRO & C3
linearization guarantees this; violation raises \texttt{TypeError} at
class definition \\
MRO totality & Every class has a linearizable MRO & C3 fails for
unlinearizable diamonds; \texttt{TypeError} at class definition \\
\texttt{isinstance} correctness & \texttt{isinstance(x,\ T)} iff
\texttt{type(x)} in T's subclass set & Definitional in Python's data
model \\
\end{longtable}

A program violating any of these axioms fails at class definition time
with \texttt{TypeError}. Such a program is not a valid Python
program; it cannot be executed. Therefore, our theorems apply to
\emph{all valid programs}. \qed

\textbf{Corollary 8.1b (Axiom Scope).} A claim that the axioms are too
strong would require exhibiting: 1. A valid, executable Python program
where the axioms fail, AND 2. A scenario where this program requires
typing discipline analysis.

Programs where axioms fail are not valid programs; they crash at
definition time. The axioms characterize well-formed programs, which is
the standard scope for type system analysis.

\textbf{Comparison to prior art.} This methodology is standard in
mechanized verification: - \textbf{CompCert} (verified C compiler):
Assumes input is well-typed C - \textbf{seL4} (verified microkernel):
Assumes hardware behaves according to spec - \textbf{CakeML} (verified
ML compiler): Assumes input parses successfully

We follow the same pattern: assume the input is a valid program
(accepted by Python's runtime), prove properties of that program.
Proving that Python's parser and class system are correct is out of
scope, and unnecessary, as Python's semantics are the \emph{definition}
of what we're modeling.

\subsection{The Typing Discipline
Hierarchy}\label{the-typing-discipline-hierarchy}

Theorem 2.10d establishes that $\{S\}$-only incoherent typing (duck typing) is incoherent. Theorem 2.10g
establishes that $\{S\}$-only typing with declared interfaces (structural typing) is eliminable when
\(B \neq \emptyset\). Together, these results collapse the space of
valid typing disciplines.

\textbf{The complete hierarchy:}

\small
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2292}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2708}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Discipline
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Coherent?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Eliminable?
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
When Valid
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
$\{S\}$-incoherent (\(\{S\}\), incoherent) & No (Thm 2.10d) & N/A & Never \\
$\{S\}$-declared (\(\{S\}\), coherent) & Yes & Yes, when \(B \neq \emptyset\) (Thm
2.10g) & Only when \(B = \emptyset\) \\
$\{B,S\}$ (\(\{B, S\}\), coherent) & Yes & No & Always (when
\(B \neq \emptyset\)) \\
\end{longtable}

\textbf{Remark:} Traditional terms: Duck typing, Structural typing, Nominal typing.

\textbf{$\{S\}$-only incoherent typing} is incoherent: no declared interface, no complete
compatibility predicate, no position on structure-semantics
relationship. This is never valid.

\textbf{Remark:} Traditional term: duck typing.

\textbf{$\{S\}$-only declared typing (Protocol)} is coherent but eliminable: for
any system using Protocol at boundaries, there exists an equivalent
system using $\{B,S\}$ typing with explicit adapters (Theorem 2.10g). The
only ``value'' of Protocol is avoiding the 2-line adapter class.
Convenience is not a capability.

\textbf{Remark:} Traditional terms: structural typing vs nominal typing.

\textbf{$\{B,S\}$ typing (ABC)} is coherent and non-eliminable: it is the
only necessary discipline for systems with inheritance.

\textbf{Remark:} Traditional term: nominal typing.

\textbf{The eliminability argument.} When integrating third-party type
\(T\) that cannot inherit from your ABC:

\begin{verbatim}
# Structural approach (Protocol) - implicit
@runtime_checkable
class Configurable(Protocol):
    def validate(self) -> bool: ...

isinstance(their_obj, Configurable)  # Hope methods match
\end{verbatim}

\begin{verbatim}
# Nominal approach (Adapter) - explicit
class TheirTypeAdapter(TheirType, ConfigurableABC):
    pass  # 2 lines. Now in your hierarchy.

adapted = TheirTypeAdapter(their_obj)  # Explicit boundary
isinstance(adapted, ConfigurableABC)   # Nominal check
\end{verbatim}

The adapter approach is strictly more explicit. ``Explicit is better
than implicit'' (Zen of Python). Protocol's only advantage (avoiding
the adapter) is a convenience, not a typing capability.

\textbf{Languages without inheritance.} Go's struct types have
\(B = \emptyset\) by design. $\{S\}$-only declared typing with declared interfaces
is the only coherent option. Go does not use $\{S\}$-only incoherent typing; Go interfaces
are declared \cite{goSpec}. This is why Go's type system is sound
despite lacking inheritance.

\textbf{Remark:} Traditional terms: structural typing, duck typing.

\textbf{The final collapse.} For languages with inheritance
(\(B \neq \emptyset\)): - $\{S\}$-only incoherent typing: incoherent, never valid -
$\{S\}$-only declared typing: coherent but eliminable, valid only as convenience -
$\{B,S\}$ typing: coherent and necessary

\textbf{Remark:} Traditional terms: duck typing, structural typing, nominal typing.

The only \emph{necessary} typing discipline is $\{B,S\}$. Everything else
is either incoherent ($\{S\}$-only incoherent typing) or reducible to $\{B,S\}$ with trivial
adapters ($\{S\}$-only declared typing).

\textbf{Remark:} Traditional terms: nominal, duck typing, structural typing.

\subsection{Future Work}\label{future-work}

\textbf{Gradual $\{B,S\}$/$\{S\}$-declared typing.} TypeScript supports both
$\{B,S\}$ (via branding) and $\{S\}$-only declared typing in the same program.
Formalizing the interaction between these disciplines, and proving
soundness of gradual migration, would enable principled adoption
strategies.

\textbf{Remark:} Traditional terms: nominal, structural typing.

\textbf{Trait systems.} Rust traits and Scala traits provide multiple
inheritance of behavior without nominal base classes. Our theorems apply
to Python's MRO, but trait resolution uses different algorithms.
Extending our complexity bounds to trait systems would broaden
applicability.

\textbf{Automated complexity inference.} Given a type system
specification, can we automatically compute whether error localization
is O(1) or \(\Omega\)(n)? Such a tool would help language designers
evaluate typing discipline tradeoffs during language design.

\textbf{Axis-parameterized type systems.} The universal principle (Section~\ref{the-classification-problem}) establishes that all fixed-axis systems are incomplete. The correct architecture is \(L : \text{AxisSet} \to \text{TypeSystem}\), where axes are injected rather than hardcoded. Future work includes:

\begin{enumerate}
\item \textbf{Formalizing axis-parameterized type systems in Lean 4.} The \texttt{axis\_framework.lean} file proves the Fixed Axis Incompleteness and Parameterized Immunity theorems. Extending this to a full type system formalization would provide machine-checked guarantees for domain-agnostic configuration systems.

\item \textbf{OpenHCS parameterization.} Refactoring OpenHCS from fixed \(\{B, S, H\}\) to parameterized axis injection. The architecture would become \texttt{OpenHCS : AxisSet -> ConfigurationSystem}, instantiated with \(\{B, S, H\}\) for current domains but extensible to temporal versioning, security contexts, or resource affinity axes without framework modification.

\item \textbf{Python \texttt{type()} extension (PEP proposal).} Python's class constructor \texttt{type(name, bases, namespace)} hardcodes a fixed axis set: \(B\) (bases) and \(S\) (namespace). This is a fixed-axis design. We propose extending the signature to:

\begin{verbatim}
type(name, bases, namespace, **axes)
\end{verbatim}

This would allow axis injection at type creation time:
\begin{verbatim}
# Current: fixed {B, S}
Foo = type("Foo", (Bar,), {"x": 1})

# Proposed: parameterized axes
Foo = type("Foo", (Bar,), {"x": 1},
           hierarchy=ctx,        # H axis: containment position
           version=v,            # Temporal axis
           provenance=chain)     # Provenance axis
\end{verbatim}

The \texttt{**axes} parameter would be accessible via \texttt{cls.\_\_axes\_\_} and introspectable at runtime. This enables: (a) domain-specific axis requirements declared at the type level, (b) framework code parameterized over arbitrary axes, and (c) gradual adoption; existing code uses the 3-argument form unchanged.

A formal PEP would specify: (i) storage semantics (\texttt{\_\_axes\_\_} dict), (ii) inheritance behavior (axis merging vs. override), (iii) metaclass interaction, and (iv) static type checker support (\texttt{typing.Axes}). The mathematical foundation is provided by the Fixed Axis Incompleteness theorem: Python's current \texttt{type()} will fail for domains requiring axes outside \(\{B, S\}\). Parameterization eliminates this impossibility wall.
\end{enumerate}

\subsection{Implications for Language
Design}\label{implications-for-language-design}

Language designers face a fundamental choice: provide nominal typing
(enabling provenance), structural typing (for \(B = \emptyset\)
boundaries), or both. Our theorems inform this decision:

\textbf{Provide both mechanisms.} Languages like TypeScript demonstrate
that nominal and structural typing can coexist. TypeScript's
``branding'' idiom (using private fields to create nominal distinctions)
validates our thesis: programmers need nominal identity even in
structurally-typed languages. Python provides both ABCs (nominal) and
\texttt{Protocol} (structural). Our theorems clarify the relationship:
when \(B \neq \emptyset\), $\{B,S\}$ typing (ABCs) strictly dominates
Protocol (Theorem 2.10j). Protocol provides convenience (avoiding adapters)
but this is not a capability; ABCs can also integrate external types via
adapters. Protocol is dominated: it provides a strict subset of capabilities.

\textbf{Remark:} In Python, ABCs implement $\{B,S\}$ typing (nominal), while Protocols implement $\{S\}$-only typing (structural).

\textbf{MRO-based resolution is near-optimal.} Python's descriptor
protocol combined with C3 linearization achieves O(1) field resolution
while preserving provenance. Languages designing new metaobject
protocols should consider whether they can match this complexity bound.

\textbf{Explicit \texttt{bases} makes $\{B,S\}$ typing strictly optimal.} If a language
exposes explicit inheritance declarations (\texttt{class\ C(Base)}),
Theorem 3.4 (Axis Inclusion Dominance) applies: $\{B,S\}$ typing strictly
dominates $\{S\}$-only typing. Language designers cannot add inheritance
to a structurally-typed language without creating capability gaps that
$\{B,S\}$ typing would eliminate.

\textbf{Remark:} In type system terminology, $\{B,S\}$ and $\{S\}$ correspond to nominal and structural typing respectively.

\subsection{Derivable Code Quality
Metrics}\label{derivable-code-quality-metrics}

The formal model yields four measurable metrics that can be computed
statically from source code:

\textbf{Metric 1: Duck Typing Density (DTD)}

\begin{verbatim}
DTD = hasattr_calls / KLOC
\end{verbatim}

Measures ad-hoc capability probing. High DTD where \(B \neq \emptyset\)
indicates discipline violation. We count only \texttt{hasattr()}, not
\texttt{getattr()} or \texttt{try/except AttributeError}, because
\texttt{hasattr()} is specifically capability detection (``does this
object have this attribute?''), the operational signature of $\{S\}$-only
typing (Definition 2.10c). \texttt{getattr()} without a fallback is
explicit attribute access; \texttt{getattr()} with a fallback or
\texttt{try/except AttributeError} may indicate $\{S\}$-only typing but also
appear in legitimate metaprogramming (descriptors, \texttt{\_\_getattr\_\_}
hooks, optional feature detection at system boundaries). The theorem
backing (Theorem 2.10d) establishes \texttt{hasattr()} as the incoherent
probe; other patterns require case-by-case analysis.

\textbf{Remark:} "Duck typing" is traditional terminology for $\{S\}$-only typing.

\textbf{Metric 2: $\{B,S\}$ Typing Ratio (BTR)}

\begin{verbatim}
BTR = (isinstance_calls + type_as_dict_key + abc_registrations) / KLOC
\end{verbatim}

Measures explicit type contracts. High BTR indicates intentional use of
inheritance hierarchy.

\textbf{Remark:} Previously called "Nominal Typing Ratio (NTR)". In type system terminology, $\{B,S\}$ typing corresponds to nominal typing.

\textbf{Metric 3: Provenance Capability (PC)} Binary metric: does the
codebase contain queries of the form ``which type provided this value''?
Presence of \texttt{(value,\ scope,\ source\_type)} tuples, MRO
traversal for resolution, or \texttt{type(obj).\_\_mro\_\_} inspection
indicates PC = 1. If PC = 1, nominal typing is mandatory (Corollary
6.3).

\textbf{Metric 4: Resolution Determinism (RD)}

\begin{verbatim}
RD = mro_based_dispatch / (mro_based_dispatch + runtime_probing_dispatch)
\end{verbatim}

Measures O(1) vs \(\Omega\)(n) error localization. RD = 1 indicates all
dispatch is MRO-based (nominal). RD = 0 indicates all dispatch is
runtime probing (duck).

\textbf{Tool implications:} These metrics enable automated linters. A
linter could flag \texttt{hasattr()} in any code where
\(B \neq \emptyset\) (DTD violation), suggest \texttt{isinstance()}
replacements, and verify that provenance-tracking codebases maintain NTR
above a threshold.

\textbf{Empirical application:} In OpenHCS, DTD dropped from 47 calls in
the UI layer (before PR \#44) to 0 after migration. NTR increased
correspondingly. PC = 1 throughout (dual-axis resolver requires
provenance). RD = 1 (all dispatch is MRO-based).

\subsection{Hybrid Systems and Methodology
Scope}\label{hybrid-systems-and-methodology-scope}

Our theorems establish necessary conditions for provenance-tracking
systems. This section clarifies the relationship between dominance and
practical constraints; shape-based typing is never an alternative, only
a sacrifice forced by external constraints.

\paragraph{8.6.1 Structural Typing Is Eliminable (Theorem
2.10g)}\label{structural-typing-is-eliminable-theorem-2.10g}

\textbf{Critical update:} Per Theorem 2.10g, structural typing is
\emph{eliminable} when \(B \neq \emptyset\). The scenarios below
describe when Protocol is \emph{convenient}, not when it is
\emph{necessary}. In all cases, the explicit adapter approach (Section
8.2) is available and strictly more explicit.

\textbf{Retrofit scenarios.} When integrating independently developed
components that share no common base classes, you cannot mandate
inheritance directly. However, you \emph{can} wrap at the boundary:
\texttt{class\ TheirTypeAdapter(TheirType,\ YourABC):\ pass}. Protocol
is a convenience that avoids this 2-line adapter. Duck typing is never
acceptable.

\textbf{Language boundaries.} Calling from Python into C libraries,
where inheritance relationships are unavailable. The C struct has no
\texttt{bases} axis. You can still wrap at ingestion: create a Python
adapter class that inherits from your ABC and delegates to the C struct.
Protocol avoids this wrapper but does not provide capabilities the
wrapper lacks.

\textbf{Versioning and compatibility.} When newer code must accept older
types that predate a base class introduction, you can create versioned
adapters:
\texttt{class\ V1ConfigAdapter(V1Config,\ ConfigBaseV2):\ pass}.
Protocol avoids this but does not provide additional capabilities.

\textbf{Type-level programming without runtime overhead.} TypeScript's
structural typing enables type checking at compile time without runtime
cost. For TypeScript code that never uses \texttt{instanceof} or class
identity (effectively \(B = \emptyset\) at runtime), structural typing
has no capability gap because there's no \(B\) to lose. However, see
Section 8.7 for why TypeScript's \emph{class-based} structural typing
creates tension; once you have \texttt{class\ extends}, you have
\(B \neq \emptyset\).

\textbf{Summary.} In all scenarios with \(B \neq \emptyset\), the
adapter approach is available. Protocol's only advantage is avoiding the
adapter. Avoiding the adapter is a convenience, not a typing capability
(Corollary 2.10h).

\paragraph{\texorpdfstring{8.6.2 The \(B \neq \emptyset\) vs
\(B = \emptyset\)
Criterion}{8.6.2 The B \backslash neq \backslash emptyset vs B = \backslash emptyset Criterion}}\label{the-b-neq-emptyset-vs-b-emptyset-criterion}

The only relevant question is whether inheritance exists:

\textbf{\(B \neq \emptyset\) (inheritance exists):} Nominal typing is
correct. Adapters handle external types (Theorem 2.10j). Examples: -
OpenHCS config hierarchy:
\texttt{class\ PathPlanningConfig(GlobalConfigBase)} - External library
types: wrap with
\texttt{class\ TheirTypeAdapter(TheirType,\ YourABC):\ pass}

\textbf{\(B = \emptyset\) (no inheritance):} Structural typing is the
only option. Examples: - JSON objects from external APIs - Go interfaces
- C structs via FFI

The ``greenfield vs retrofit'' framing is obsolete (see Remark after
Theorem 3.62).

\paragraph{8.6.3 System Boundaries}\label{system-boundaries}

Systems have \(B \neq \emptyset\) components (internal hierarchies) and
\(B = \emptyset\) boundaries (external data):

\begin{verbatim}
# B != {}: internal config hierarchy (use nominal)
class ConfigBase(ABC):
    @abstractmethod
    def validate(self) -> bool: pass

class PathPlanningConfig(ConfigBase):
    well_filter: Optional[str]

# B = {}: parse external JSON (structural is only option)
def load_config_from_json(json_dict: Dict[str, Any]) -> ConfigBase:
    # JSON has no inheritance; structural validation at boundary
    if "well_filter" in json_dict:
        return PathPlanningConfig(**json_dict)  # Returns nominal type
    raise ValueError("Invalid config")
\end{verbatim}

The JSON parsing layer is \(B = \emptyset\) (JSON has no inheritance).
The return value is \(B \neq \emptyset\) (ConfigBase hierarchy). This is
correct: structural at data boundaries where \(B = \emptyset\), nominal
everywhere else.

\paragraph{8.6.4 Scope Summary}\label{scope-summary}

\small
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4286}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3571}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Context
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Typing Discipline
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Justification
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(B \neq \emptyset\) (any language with inheritance) & Nominal
(mandatory) & Theorem 2.18 (strict dominance), Theorem 2.10j (adapters
dominate Protocol) \\
\(B = \emptyset\) (Go, JSON, pure structs) & Structural (correct) &
Theorem 3.1 (namespace-only) \\
Language boundaries (C/FFI) & Structural (mandatory) & No inheritance
available (\(B = \emptyset\) at boundary) \\
\end{longtable}

\textbf{Removed rows:} - ``Retrofit / external types $\rightarrow$ Structural
(acceptable)''. Adapters exist (Theorem 2.10j); structural is dominated.
``Small scripts / prototypes $\rightarrow$ Duck (acceptable)''.
Duck typing is incoherent for B-dependent queries (Theorem 2.10d).

The methodology states: \textbf{if \(B \neq \emptyset\), nominal typing
is the capability-maximizing choice.} Protocol is dominated. Duck typing
is incoherent. The decision follows from the capability analysis, not
from project size or aesthetic preference.

\subsection{Case Study: TypeScript's Design
Tension}\label{case-study-typescripts-design-tension}

TypeScript presents a puzzle: it has explicit inheritance
(\texttt{class\ B\ extends\ A}) but uses structural subtyping. Is this a
valid design tradeoff, or an architectural tension with measurable
consequences?
The runtime model (JavaScript prototypes) preserves \(B\) and nominal
identity (via \texttt{instanceof}), while the static checker erases \(B\)
when computing compatibility
\cite{tsHandbookTypeCompatibility,bierman2014typescript}. Per
Definition 8.3 this is incoherence.

\textbf{Definition 8.3 (Type System Coherence).} A type system is
\emph{coherent} with respect to a language construct if the type
system's judgments align with the construct's runtime semantics.
Formally: if construct \(C\) creates a runtime distinction between
entities \(A\) and \(B\), a coherent type system also distinguishes
\(A\) and \(B\).

\textbf{Definition 8.4 (Type System Tension).} A type system exhibits
\emph{tension} when it is incoherent (per Definition 8.3) AND users
create workarounds to restore the missing distinctions.

\paragraph{8.7.1 The Tension Analysis}\label{the-tension-analysis}

TypeScript's design exhibits three measurable tensions:

\textbf{Tension 1: Incoherence per Definition 8.3.}

\begin{verbatim}
class A { x: number = 1; }
class B { x: number = 1; }

// Runtime: instanceof creates distinction
const b = new B();
console.log(b instanceof A);  // false - different classes

// Type system: no distinction
function f(a: A) { }
f(new B());  // OK - same structure
\end{verbatim}

The \texttt{class} keyword creates a runtime distinction
(\texttt{instanceof} returns \texttt{false}). The type system does not
reflect this distinction. Per Definition 8.3, this is incoherence: the
construct (\texttt{class}) creates a runtime distinction that the type
system ignores.

\textbf{Tension 2: Workaround existence per Definition 8.4.}

TypeScript programmers use ``branding'' to restore nominal distinctions:

\begin{verbatim}
// Workaround: add a private field to force nominal distinction
class StepWellFilterConfig extends WellFilterConfig {
    private __brand!: void;  // Forces nominal identity
}

// Now TypeScript treats them as distinct (private field differs)
\end{verbatim}

The existence of this workaround demonstrates Definition 8.4: users
create patterns to restore distinctions the type system fails to
provide. TypeScript GitHub issue \#202 (2014) and PR \#33038 (2019)
request or experiment with native nominal types
\cite{tsIssue202,tsPR33038}, confirming the workaround is widespread.

\textbf{Tension 3: Measurable consequence.}

The \texttt{extends} keyword is provided but ignored by the type
checker. This is information-theoretically suboptimal per our framework:
the programmer declares a distinction (\texttt{extends}), the type
system discards it, then the programmer re-introduces a synthetic
distinction (\texttt{\_\_brand}). The same information is encoded twice
with different mechanisms.

\paragraph{8.7.2 Formal Characterization}\label{formal-characterization}

\textbf{Theorem 8.7 (TypeScript Incoherence).} TypeScript's class-based
type system is incoherent per Definition 8.3.

\emph{Proof.} 1. TypeScript's \texttt{class\ A} creates a runtime entity
with nominal identity (JavaScript prototype) 2. \texttt{instanceof\ A}
checks this nominal identity at runtime 3. TypeScript's type system uses
structural compatibility for class types 4. Therefore: runtime
distinguishes \texttt{A} from structurally-identical \texttt{B}; type
system does not 5. Per Definition 8.3, this is incoherence.
\qed

\textbf{Corollary 8.7.1 (Branding Validates Tension).} The prevalence of
branding patterns in TypeScript codebases empirically validates the
tension per Definition 8.4.

\emph{Evidence.} TypeScript GitHub issue \#202 (2014, 1,200+ reactions)
and PR \#33038 (2019) request native nominal types
\cite{tsIssue202,tsPR33038}. The \texttt{@types} ecosystem includes
branded type utilities (\texttt{ts-brand}, \texttt{io-ts}). This is
observed community behavior consistent with the predicted tension.

\paragraph{8.7.3 Implications for Language
Design}\label{implications-for-language-design-1}

TypeScript's tension is an intentional design decision for JavaScript
interoperability. The structural type system allows gradual adoption in
untyped JavaScript codebases. However, TypeScript has \texttt{class}
with \texttt{extends}, meaning \(B \neq \emptyset\). Our theorems
apply: $\{B,S\}$ typing strictly dominates (Theorem 3.5).

The tension manifests in practice: programmers use \texttt{class}
expecting $\{B,S\}$ semantics, receive $\{S\}$-only semantics, then add
branding to restore $\{B,S\}$ behavior. Our theorems predict this: Theorem
3.4 shows that when \texttt{bases} exist, $\{B,S\}$ typing strictly
dominates $\{S\}$-only typing; TypeScript violates this optimality,
causing measurable friction. The branding idiom is programmers manually
recovering capabilities the language architecture foreclosed.

\textbf{Remark:} In type system terminology, $\{B,S\}$ and $\{S\}$ correspond to nominal and structural typing.

\textbf{The lesson:} Languages adding \texttt{class} syntax should
consider whether their type system will be coherent (per Definition 8.3)
with the runtime semantics of class identity. $\{S\}$-only typing is
correct for languages without inheritance (Go). For languages with
inheritance, coherence requires $\{B,S\}$ typing or explicit documentation
of the intentional tension.

\subsection{Mixins with MRO Strictly Dominate Object
Composition}\label{mixins-with-mro-strictly-dominate-object-composition}

The ``composition over inheritance'' principle from the Gang of Four~\cite{gamma1994design} has become software engineering dogma. We demonstrate this
principle is incorrect for behavior extension in languages with explicit
MRO.

\paragraph{8.8.1 Formal Model: Mixin vs
Composition}\label{formal-model-mixin-vs-composition}

\textbf{Definition 8.1 (Mixin).} A mixin is a class designed to provide
behavior via inheritance, with no standalone instantiation. Mixins are
composed via the bases axis, resolved deterministically via MRO.

\begin{verbatim}
# Mixin: behavior provider via inheritance
class LoggingMixin:
    def process(self):
        print(f"Logging: {self}")
        super().process()

class CachingMixin:
    def process(self):
        if cached := self._check_cache():
            return cached
        result = super().process()
        self._cache(result)
        return result

# Composition via bases (single decision point)
class Handler(LoggingMixin, CachingMixin, BaseHandler):
    pass  # MRO: Handler -> Logging -> Caching -> Base
\end{verbatim}

\textbf{Definition 8.2 (Object Composition).} Object composition
delegates to contained objects, with manual call-site dispatch for each
behavior.

\begin{verbatim}
# Composition: behavior provider via delegation
class Handler:
    def __init__(self):
        self.logger = Logger()
        self.cache = Cache()

    def process(self):
        self.logger.log(self)  # Manual dispatch point 1
        if cached := self.cache.check():  # Manual dispatch point 2
            return cached
        result = self._do_process()
        self.cache.store(key, result)  # Manual dispatch point 3
        return result
\end{verbatim}

\paragraph{8.8.2 Capability Analysis}\label{capability-analysis}

\textbf{What composition provides:} 1. {[}PASS{]} Behavior extension
(via delegation) 2. {[}PASS{]} Multiple behaviors combined

\textbf{What mixins provide:} 1. {[}PASS{]} Behavior extension (via
super() linearization) 2. {[}PASS{]} Multiple behaviors combined 3.
{[}PASS{]} \textbf{Deterministic conflict resolution} (C3 MRO).
\textbf{Composition cannot provide} 4. {[}PASS{]} \textbf{Single
decision point} (class definition). \textbf{Composition has n call
sites} 5. {[}PASS{]} \textbf{Provenance via MRO} (which mixin provided
this behavior?). \textbf{Composition cannot provide} 6. {[}PASS{]}
\textbf{Exhaustive enumeration} (list all mixed-in behaviors via
\texttt{\_\_mro\_\_}). \textbf{Composition cannot provide}

\textbf{Addressing runtime swapping:} A common objection is that
composition allows ``swapping implementations at runtime''
(\texttt{handler.cache\ =\ NewCache()}). This is orthogonal to the
dominance claim for two reasons:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Mixins can also swap at runtime} via class mutation:
  \texttt{Handler.\_\_bases\_\_\ =\ (NewLoggingMixin,\ CachingMixin,\ BaseHandler)}
  or via \texttt{type()} to create a new class dynamically. Python's
  class system is mutable.
\item
  \textbf{Runtime swapping is a separate axis.} The dominance claim
  concerns \emph{static behavior extension}: adding logging, caching,
  validation to a class. Whether to also support runtime reconfiguration
  is an orthogonal requirement. Systems requiring runtime swapping can
  use mixins for static extension AND composition for swappable
  components. The two patterns are not mutually exclusive.
\end{enumerate}

Therefore: \textbf{Mixin capabilities \(\supset\) Composition
capabilities} (strict superset) for static behavior extension.

\textbf{Theorem 8.1 (Mixin Dominance).} For static behavior extension in
languages with deterministic MRO, mixin composition strictly dominates
object composition.

\emph{Proof.} Let \(\mathcal{M}\) = capabilities of mixin composition
(inheritance + MRO). Let \(\mathcal{C}\) = capabilities of object
composition (delegation).

Mixins provide: 1. Behavior extension (same as composition) 2.
Deterministic conflict resolution via MRO (composition cannot provide)
3. Provenance via MRO position (composition cannot provide) 4. Single
decision point for ordering (composition has \(n\) decision points) 5.
Exhaustive enumeration via \texttt{\_\_mro\_\_} (composition cannot
provide)

Therefore \(\mathcal{C} \subset \mathcal{M}\) (strict subset). By the
same argument as Theorem 3.5 (Strict Dominance), choosing composition
forecloses capabilities for zero benefit. \qed

\textbf{Corollary 8.1.1 (Runtime Swapping Is Orthogonal).} Runtime
implementation swapping is achievable under both patterns: via object
attribute assignment (composition) or via class mutation/dynamic type
creation (mixins). Neither pattern forecloses this capability.

\paragraph{8.8.3 Connection to Typing
Discipline}\label{connection-to-typing-discipline}

\textbf{The parallel to Theorem 3.5 is exact:}

\small
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4634}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5366}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Typing Disciplines
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Architectural Patterns
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Structural typing checks only namespace (shape) & Composition checks
only namespace (contained objects) \\
Nominal typing checks namespace + bases (MRO) & Mixins check namespace +
bases (MRO) \\
Structural cannot provide provenance & Composition cannot provide
provenance \\
Nominal strictly dominates & Mixins strictly dominate \\
\end{longtable}

\textbf{Theorem 8.2 (Unified Dominance Principle).} In class systems
with explicit inheritance (bases axis), mechanisms using bases strictly
dominate mechanisms using only namespace.

\emph{Proof.} Let \(B\) = bases axis, \(S\) = namespace axis. Let
\(D_S\) = discipline using only \(S\) (structural typing or
composition). Let \(D_B\) = discipline using \(B + S\) (nominal typing
or mixins).

\(D_S\) can only distinguish types/behaviors by namespace content.
\(D_B\) can distinguish by namespace content AND position in inheritance
hierarchy.

Therefore \(\text{capabilities}(D_S) \subset \text{capabilities}(D_B)\)
(strict subset). \qed

\subsection{Validation: Alignment with Python's Design
Philosophy}\label{validation-alignment-with-pythons-design-philosophy}

Our formal results align with Python's informal design philosophy,
codified in PEP 20 (``The Zen of Python''). This alignment validates
that the abstract model captures real constraints.

\textbf{``Explicit is better than implicit''} (Zen line 2). ABCs require
explicit inheritance declarations (\texttt{class\ Config(ConfigBase)}),
making type relationships visible in code. Duck typing relies on
implicit runtime checks
(\texttt{hasattr(obj,\ \textquotesingle{}validate\textquotesingle{})}),
hiding conformance assumptions. Our Theorem 3.5 formalizes this:
explicit nominal typing provides capabilities that implicit shape-based
typing cannot.

\textbf{``In the face of ambiguity, refuse the temptation to guess''}
(Zen line 12). Duck typing \emph{guesses} interface conformance via
runtime attribute probing. Nominal typing refuses to guess, requiring
declared conformance. Our provenance impossibility result (Corollary
6.3) proves that guessing cannot distinguish structurally identical
types with different inheritance.

\textbf{``Errors should never pass silently''} (Zen line 10). ABCs
fail-loud at instantiation
(\texttt{TypeError:\ Can\textquotesingle{}t\ instantiate\ abstract\ class\ with\ abstract\ method\ validate}).
Duck typing fails-late at attribute access, possibly deep in the call
stack. Our complexity theorems (Section 4) formalize this: nominal
typing has O(1) error localization, while duck typing has \(\Omega\)(n)
error sites.

\textbf{``There should be one-- and preferably only one --obvious way to
do it''} (Zen line 13). Our decision procedure (Section 2.5.1) provides
exactly one obvious way: when \(B \neq \emptyset\), use nominal typing.

\textbf{Historical validation:} Python's evolution confirms our
theorems. Python 1.0 (1991) had only duck typing, an incoherent
non-discipline (Theorem 2.10d). Python 2.6 (2007) added ABCs because
duck typing was insufficient for large codebases. Python 3.8 (2019)
added Protocols for retrofit scenarios; coherent structural typing to
replace incoherent duck typing. This evolution from incoherent
\(\rightarrow\) nominal \(\rightarrow\) nominal+structural exactly
matches our formal predictions.

\subsection{Connection to Gradual
Typing}\label{connection-to-gradual-typing}

Our results connect to the gradual typing literature (Siek \& Taha 2006,
Wadler \& Findler 2009). Gradual typing addresses adding types to
existing untyped code. Our theorems address which discipline to use when
\(B \neq \emptyset\).

\textbf{The complementary relationship:}

\small
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2564}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3846}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3590}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Scenario
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Gradual Typing
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Our Theorems
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Untyped code (\(B = \emptyset\)) & {[}PASS{]} Applicable & {[}N/A{]} No
inheritance \\
Typed code (\(B \neq \emptyset\)) & {[}N/A{]} Already typed & {[}PASS{]}
Nominal dominates \\
\end{longtable}

\textbf{Gradual typing's insight:} When adding types to untyped code,
the dynamic type \texttt{?} allows gradual migration. This applies when
\(B = \emptyset\) (no inheritance structure exists yet).

\textbf{Our insight:} When \(B \neq \emptyset\), nominal typing strictly
dominates. This includes ``retrofit'' scenarios with external
types; adapters make nominal typing available (Theorem 2.10j).

\textbf{The unified view:} Gradual typing and nominal typing address
orthogonal concerns: - Gradual typing: Typed vs untyped
(\(B = \emptyset\) $\rightarrow$ \(B \neq \emptyset\) migration) - Our theorems:
Which discipline when \(B \neq \emptyset\) (answer: nominal)

\textbf{Theorem 8.3 (Gradual-Nominal Complementarity).} Gradual typing
and nominal typing are complementary, not competing. Gradual typing
addresses the presence of types; our theorems address which types to
use.

\emph{Proof.} Gradual typing's dynamic type \texttt{?} allows structural
compatibility with untyped code where \(B = \emptyset\). Once
\(B \neq \emptyset\) (inheritance exists), our theorems apply: nominal
typing strictly dominates (Theorem 3.5), and adapters eliminate the
retrofit exception (Theorem 2.10j). The two address different questions.
\qed

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Connection to Leverage Framework}\label{sec:leverage-connection}

The strict dominance of nominal typing (Theorem 2.10j) is an instance of a more
general principle: \emph{leverage maximization}.

Define \textbf{leverage} as $L = |\text{Capabilities}| / \text{DOF}$, where DOF
(Degrees of Freedom) counts independent encoding locations for type information.
Both typing disciplines have similar DOF (both require type declarations at use
sites), but nominal typing provides 4 additional capabilities (provenance,
identity, enumeration, conflict resolution). Therefore:
\[
L(\text{nominal}) = \frac{5}{1} > \frac{1}{1} = L(\text{duck})
\]

The leverage framework (see companion paper) proves that for any architectural
decision, the optimal choice maximizes leverage. This paper proves the
\emph{instance}; the companion paper proves the \emph{metatheorem} that leverage
maximization is universally optimal.

\textbf{Theorem 8.4 (Typing as Leverage Instance).} The strict dominance of
nominal typing (Theorem 2.10j) is an instance of the Leverage Maximization
Principle.

\emph{Proof.} By Theorem 2.10j, nominal typing provides a strict superset of
capabilities at equivalent cost. This is exactly the condition for higher
leverage: $L(\text{nominal}) > L(\text{duck})$. By the Leverage Maximization
Principle, nominal typing is therefore optimal. \qed
