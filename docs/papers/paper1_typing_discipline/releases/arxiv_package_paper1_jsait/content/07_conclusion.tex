This paper presents an information-theoretic analysis of classification under observational constraints. We prove three main results:

\begin{enumerate}
\item \textbf{Information Barrier}: Observers limited to attribute-membership queries cannot compute properties that vary within indistinguishability classes. This is universal: it applies to biological taxonomy, database systems, library classification, and programming language runtimes alike.

\item \textbf{Witness Optimality}: Nominal-tag observers achieve $W(\text{identity}) = O(1)$, the minimum witness cost. The gap from attribute-only observation ($\Omega(d)$, with a worst-case family where $d = n$) is unbounded.

\item \textbf{Matroid Structure}: Minimal distinguishing query sets form the bases of a matroid. The distinguishing dimension of a classification problem is well-defined and computable.
\end{enumerate}

\subsection{The Universal Pattern}

Across domains, the same structure recurs:

\begin{itemize}
\item \textbf{Biology}: Phenotypic observation cannot distinguish cryptic species. DNA barcoding (nominal tag) resolves them in $O(1)$.

\item \textbf{Databases}: Column-value queries cannot distinguish rows with identical attributes. Primary keys (nominal tag) provide $O(1)$ identity.

\item \textbf{Type systems}: Interface observation cannot distinguish structurally identical types. Type tags provide $O(1)$ identity.
\end{itemize}

The information barrier is not a quirk of any particular domain; it is a mathematical necessity arising from the quotient structure induced by limited observations.

\subsection{Implications}

\begin{itemize}
\item \textbf{The necessity of nominal information is a theorem, not a preference.} Any zero-error scheme must satisfy the ambiguity converse $L \ge \log_2 A_\pi$ (Theorem~\ref{thm:converse}), where $A_\pi$ is the largest collision block induced by observable profiles. In maximal-barrier domains ($A_\pi = k$), this becomes $L \ge \log_2 k$ and nominal tagging gives the unique $D=0$ Pareto point with $W=O(1)$ (Theorem~\ref{thm:lwd-optimal}).

\item \textbf{The barrier is informational, not computational}: even with unbounded resources, attribute-only observers cannot overcome it.

\item \textbf{Classification system design is constrained}: the choice of observation family determines which properties are computable.
\end{itemize}

\subsection{Future Work}

\begin{enumerate}
\item \textbf{Other classification domains}: What is the matroid structure of observation spaces in chemistry (molecular fingerprints), linguistics (phonetic features), or machine learning (feature embeddings)?

\item \textbf{Witness complexity of other properties}: Beyond identity, what are the witness costs for provenance, equivalence, or subsumption?

\item \textbf{Hybrid observers}: Can observer strategies that combine tags and attributes achieve better $(L, W, D)$ tradeoffs for specific query distributions?
\end{enumerate}

\subsection{Conclusion}

Classification under observational constraints admits a clean information-theoretic analysis. The zero-error converse is governed by collision multiplicity: any $D=0$ scheme necessarily has $L \ge \log_2 A_\pi$ (Theorem~\ref{thm:converse}). In maximal-barrier domains ($A_\pi=k$), nominal-tag observation achieves the unique Pareto-optimal $D=0$ point in the $(L, W, D)$ tradeoff (Theorem~\ref{thm:lwd-optimal}). The results are universal within the stated observation model, and all proofs are machine-verified in Lean 4.

\subsection*{AI Disclosure}

This work was developed with AI assistance (Claude, Anthropic). The AI contributed to exposition, code generation, and proof exploration. All mathematical claims were verified by the authors and machine-checked in Lean 4. The Lean proofs are the authoritative source; no theorem depends solely on AI-generated reasoning.
