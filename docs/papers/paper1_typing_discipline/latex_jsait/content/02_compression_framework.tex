\label{sec:framework}

\subsection{Semantic Compression: The Problem}

The fundamental problem of semantic compression is: given a value $v$ from a large space $\mathcal{V}$, how can we represent $v$ compactly while preserving the ability to answer semantic queries about $v$?

Classical rate-distortion theory \cite{shannon1959coding} studies the tradeoff between representation size (rate) and reconstruction fidelity (distortion). We extend this framework to include a third dimension: \emph{witness cost}---the number of queries required to compute a semantic property.

\subsection{The Two-Axis Model}

We adopt a two-axis model of semantic structure, where each value is characterized by:
\begin{itemize}
\item \textbf{Bases axis ($B$)}: The inheritance lineage---which types the value inherits from
\item \textbf{Structure axis ($S$)}: The interface signature---which methods/attributes the value provides
\end{itemize}

\begin{definition}[Two-axis representation]
A value $v \in \mathcal{V}$ has representation $(B(v), S(v))$ where:
\begin{align}
B(v) &= \text{MRO}(\text{type}(v)) \quad \text{(Method Resolution Order)} \\
S(v) &= \pi(v) = (q_I(v))_{I \in \mathcal{I}} \quad \text{(interface profile)}
\end{align}
\end{definition}

\begin{theorem}[Model completeness]\label{thm:model-completeness}
In any class system with explicit inheritance, the pair $(B, S)$ is complete: every semantic property of a value is a function of $(B(v), S(v))$.
\end{theorem}

\begin{proof}
The proof proceeds by showing that any additional property (e.g., module location, metadata) is either derived from $(B, S)$ or stored within the namespace (part of $S$). In Python, \texttt{type(name, bases, namespace)} is the universal type constructor, making $(B, S)$ constitutive.
\end{proof}

\subsection{Interface Equivalence and Observational Limits}

Recall from Section 1 the interface equivalence relation:

\begin{definition}[Interface equivalence (restated)]
Values $v, w \in \mathcal{V}$ are interface-equivalent, written $v \sim w$, iff $\pi(v) = \pi(w)$---i.e., they satisfy exactly the same interfaces.
\end{definition}

\begin{proposition}[Equivalence class structure]
The relation $\sim$ partitions $\mathcal{V}$ into equivalence classes. Let $\mathcal{V}/{\sim}$ denote the quotient space. An interface-only observer effectively operates on $\mathcal{V}/{\sim}$, not $\mathcal{V}$.
\end{proposition}

\begin{corollary}[Information loss quantification]
The information lost by interface-only observation is:
\[
H(\mathcal{V}) - H(\mathcal{V}/{\sim}) = H(\mathcal{V} | \pi)
\]
where $H$ denotes entropy. This quantity is positive whenever multiple types share the same interface profile.
\end{corollary}

\subsection{Witness Cost: Query Complexity for Semantic Properties}

\begin{definition}[Witness procedure]
A \emph{witness procedure} for property $P: \mathcal{V} \to Y$ is an algorithm $A$ that:
\begin{enumerate}
\item Takes as input a value $v \in \mathcal{V}$ (via query access only)
\item Makes queries to the primitive set $\Phi_{\mathcal{I}}^+$
\item Outputs $P(v)$
\end{enumerate}
\end{definition}

\begin{definition}[Witness cost]
The \emph{witness cost} of property $P$ is:
\[
W(P) = \min_{A \text{ computes } P} c(A)
\]
where $c(A)$ is the worst-case number of primitive queries made by $A$.
\end{definition}

\begin{remark}[Relationship to query complexity]
Witness cost is a form of query complexity \cite{buhrman2002complexity} specialized to semantic properties. Unlike Kolmogorov complexity, $W$ is computable and depends on the primitive set, not a universal machine.
\end{remark}

\begin{lemma}[Witness cost lower bounds]
For any property $P$:
\begin{enumerate}
\item If $P$ is interface-computable: $W(P) \leq |\mathcal{I}|$
\item If $P$ varies within some $\sim$-class: $W(P) = \infty$ for interface-only observers
\item With nominal-tag access: $W(\text{type-identity}) = O(1)$
\end{enumerate}
\end{lemma}

\subsection{Rate--Witness--Distortion Tradeoff}

We now define the three-dimensional tradeoff space that characterizes observation strategies.

\begin{definition}[Tag length (Rate)]
The \emph{tag length} $L$ is the number of machine words required to store a type identifier per value:
\[
L = \begin{cases}
O(1) & \text{if nominal tags are stored} \\
0 & \text{if no explicit tags}
\end{cases}
\]
Under a fixed word size $w$ bits, $L = O(1)$ corresponds to $\Theta(w)$ bits per value.
\end{definition}

\begin{definition}[Witness cost (Query complexity)]
The \emph{witness cost} $W$ is the minimum number of primitive queries required for type identity checking:
\[
W = W(\text{type-identity})
\]
\end{definition}

\begin{definition}[Distortion (Semantic fidelity)]
The \emph{distortion} $D$ is a worst-case semantic failure indicator:
\[
D = \begin{cases}
0 & \text{if } \forall v_1, v_2: \text{type}(v_1) = \text{type}(v_2) \Rightarrow \text{behavior}(v_1) \equiv \text{behavior}(v_2) \\
1 & \text{otherwise}
\end{cases}
\]
Here $\text{behavior}(v)$ denotes the observable behavior of $v$ under program execution (method dispatch outcomes, attribute access results).
\end{definition}

\begin{remark}[Distortion interpretation]
$D = 0$ means the observation strategy is \emph{sound}: type equality (as computed by the observer) implies behavioral equivalence. $D = 1$ means the strategy may conflate behaviorally distinct values.
\end{remark}

\subsection{The $(L, W, D)$ Tradeoff Space}

\begin{definition}[Achievable region]
A point $(L, W, D)$ is \emph{achievable} if there exists an observation strategy realizing those values. Let $\mathcal{R} \subseteq \mathbb{R}_{\geq 0} \times \mathbb{R}_{\geq 0} \times \{0, 1\}$ denote the achievable region.
\end{definition}

\begin{definition}[Pareto optimality]
A point $(L^*, W^*, D^*)$ is \emph{Pareto-optimal} if there is no achievable $(L, W, D)$ with $L \leq L^*$, $W \leq W^*$, $D \leq D^*$, and at least one strict inequality.
\end{definition}

The main result of Section~\ref{sec:rate-distortion} is that nominal-tag observation achieves the unique Pareto-optimal point with $D = 0$.

