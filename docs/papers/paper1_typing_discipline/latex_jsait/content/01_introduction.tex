\subsection{The Identification Problem}

Consider an encoder-decoder pair communicating about entities from a large universe $\mathcal{V}$. The decoder must \emph{identify} each entity---determine which of $k$ classes it belongs to---using only:
\begin{itemize}
\item A \emph{tag} of $L$ bits stored with the entity, and/or
\item \emph{Queries} to a binary oracle: ``does entity $v$ satisfy attribute $I$?''
\end{itemize}

This is not reconstruction (the decoder need not recover $v$), but \emph{identification} in the sense of Ahlswede and Dueck \cite{ahlswede1989identification}: the decoder must answer ``which class?'' with zero or bounded error.

We prove three results:
\begin{enumerate}
\item \textbf{Information barrier (capacity limit).} When the attribute profile $\pi: \mathcal{V} \to \{0,1\}^n$ is not injective on classes, the channel $C \to \pi(V)$ has $I(C; \pi(V)) < H(C)$. Zero-error identification via queries alone is impossible.
\item \textbf{Optimal tagging (achievability).} A tag of $L = \lceil \log_2 k \rceil$ bits achieves zero-error identification with $W = O(1)$ query cost. This is Pareto-optimal in the $(L, W, D)$ tradeoff space.
\item \textbf{Matroid structure (query complexity).} Minimal sufficient query sets form the bases of a matroid. The \emph{identification dimension}---common cardinality of all minimal sets---lower-bounds the query cost $W$ for any tag-free scheme.
\end{enumerate}

These results are universal: the theory applies to type systems, databases, biological taxonomy, and knowledge graphs. We develop the mathematics in full generality, then exhibit concrete instantiations.

\subsection{The Observation Model}

We formalize the observational constraint as a family of binary predicates. The terminology is deliberately abstract; concrete instantiations follow in Section~\ref{sec:applications}.

\begin{definition}[Entity space and attribute family]
Let $\mathcal{V}$ be a set of entities (program objects, database records, biological specimens, library items). Let $\mathcal{I}$ be a finite set of \emph{attributes}---observable properties that partition the entity space.
\end{definition}

\begin{remark}[Terminology]
We use ``attribute'' for the abstract concept. In type systems, attributes are \emph{interfaces} or \emph{method signatures}. In databases, they are \emph{columns}. In taxonomy, they are \emph{phenotypic characters}. In library science, they are \emph{facets}. The mathematics is identical.
\end{remark}

\begin{definition}[Interface observation family]
For each $I \in \mathcal{I}$, define the interface-membership observation $q_I: \mathcal{V} \to \{0,1\}$:
\[
q_I(v) = \begin{cases} 1 & \text{if } v \text{ satisfies interface } I \\ 0 & \text{otherwise} \end{cases}
\]
Let $\Phi_{\mathcal{I}} = \{q_I : I \in \mathcal{I}\}$ denote the interface observation family.
\end{definition}

\begin{definition}[Interface profile]
The interface profile function $\pi: \mathcal{V} \to \{0,1\}^{|\mathcal{I}|}$ maps each value to its complete interface signature:
\[
\pi(v) = (q_I(v))_{I \in \mathcal{I}}
\]
\end{definition}

\begin{definition}[Interface indistinguishability]
Values $v, w \in \mathcal{V}$ are \emph{interface-indistinguishable}, written $v \sim w$, iff $\pi(v) = \pi(w)$.
\end{definition}

The relation $\sim$ is an equivalence relation. We write $[v]_\sim$ for the equivalence class of $v$.

\begin{definition}[Interface-only observer]
An \emph{interface-only observer} is any procedure whose interaction with a value $v \in \mathcal{V}$ is limited to queries in $\Phi_{\mathcal{I}}$. Formally, the observer receives only $\pi(v)$, not $v$ itself.
\end{definition}

\subsection{The Central Question}

The central question is: \textbf{what semantic properties can an interface-only observer compute?}

A semantic property is a function $P: \mathcal{V} \to \{0,1\}$ (or more generally, $P: \mathcal{V} \to Y$ for some codomain $Y$). We say $P$ is \emph{interface-computable} if there exists a function $f: \{0,1\}^{|\mathcal{I}|} \to Y$ such that $P(v) = f(\pi(v))$ for all $v$.

\subsection{The Information Barrier}

\begin{theorem}[Information barrier]\label{thm:information-barrier}
Let $P: \mathcal{V} \to Y$ be any function. If $P$ is interface-computable, then $P$ is constant on $\sim$-equivalence classes:
\[
v \sim w \implies P(v) = P(w)
\]
Equivalently: no interface-only observer can compute any property that varies within an equivalence class.
\end{theorem}

\begin{proof}
Suppose $P$ is interface-computable via $f$, i.e., $P(v) = f(\pi(v))$ for all $v$. Let $v \sim w$, so $\pi(v) = \pi(w)$. Then:
\[
P(v) = f(\pi(v)) = f(\pi(w)) = P(w)
\]
\end{proof}

\begin{remark}[Information-theoretic nature]
The barrier is \emph{informational}, not computational. Given unlimited time, memory, and computational power, an interface-only observer still cannot distinguish $v$ from $w$ when $\pi(v) = \pi(w)$. The constraint is on the evidence itself.
\end{remark}

\begin{corollary}[Provenance is not interface-computable]\label{cor:provenance-barrier}
Let $\text{type}: \mathcal{V} \to \mathcal{T}$ be the type assignment function. If there exist values $v, w$ with $\pi(v) = \pi(w)$ but $\text{type}(v) \neq \text{type}(w)$, then type identity is not interface-computable.
\end{corollary}

\begin{proof}
Direct application of Theorem~\ref{thm:information-barrier} to $P = \text{type}$.
\end{proof}

\subsection{The Positive Result: Nominal Tagging}

We now show that augmenting interface observations with a single primitive---nominal-tag access---achieves constant witness cost.

\begin{definition}[Nominal-tag access]
A \emph{nominal tag} is a value $\tau(v) \in \mathcal{T}$ associated with each $v \in \mathcal{V}$, representing the type identity of $v$. The \emph{nominal-tag access} operation returns $\tau(v)$ in $O(1)$ time.
\end{definition}

\begin{definition}[Primitive query set]
The extended primitive query set is $\Phi_{\mathcal{I}}^+ = \Phi_{\mathcal{I}} \cup \{\tau\}$, where $\tau$ denotes nominal-tag access.
\end{definition}

\begin{definition}[Witness cost]
Let $W(P)$ denote the minimum number of primitive queries from $\Phi_{\mathcal{I}}^+$ required to compute property $P$:
\[
W(P) = \min \{ c(A) : A \text{ is a procedure computing } P \}
\]
where $c(A)$ counts the number of queries to $\Phi_{\mathcal{I}}^+$ made by $A$.
\end{definition}

\begin{theorem}[Constant witness for type identity]\label{thm:constant-witness}
Under nominal-tag access, type identity checking has constant witness cost:
\[
W(\text{type-identity}) = O(1)
\]
Specifically, the witness procedure is: return $\tau(v_1) = \tau(v_2)$.
\end{theorem}

\begin{proof}
The procedure makes exactly 2 primitive queries (one $\tau$ access per value) and one comparison. This is $O(1)$ regardless of the number of interfaces $|\mathcal{I}|$.
\end{proof}

\begin{theorem}[Interface-only lower bound]\label{thm:interface-lower-bound}
For interface-only observers, type identity checking requires:
\[
W(\text{type-identity}) = \Omega(|\mathcal{I}|)
\]
in the worst case.
\end{theorem}

\begin{proof}
Construct a family of $|\mathcal{I}|$ types where each type $T_i$ satisfies exactly the interfaces $\{I_1, \ldots, I_i\}$. Distinguishing $T_{i}$ from $T_{i+1}$ requires querying $I_{i+1}$. Thus, distinguishing all pairs requires querying all $|\mathcal{I}|$ interfaces.
\end{proof}

\subsection{Main Contributions}

This paper establishes the following results:

\begin{enumerate}
\item \textbf{Information Barrier Theorem} (Theorem~\ref{thm:information-barrier}): Interface-only observers cannot compute any property that varies within $\sim$-equivalence classes. This is an information-theoretic impossibility, not a computational limitation.

\item \textbf{Constant-Witness Theorem} (Theorem~\ref{thm:constant-witness}): Nominal-tag access achieves $W(\text{type-identity}) = O(1)$, with matching lower bound $\Omega(|\mathcal{I}|)$ for interface-only observers (Theorem~\ref{thm:interface-lower-bound}).

\item \textbf{Complexity Separation} (Section~\ref{sec:complexity}): We establish O(1) vs O(k) vs $\Omega(n)$ complexity bounds for error localization under different observation regimes.

\item \textbf{Matroid Structure} (Section~\ref{sec:matroid}): Minimal distinguishing query sets form the bases of a matroid. All such sets have equal cardinality, establishing a well-defined ``distinguishing dimension.''

\item \textbf{$(L, W, D)$ Optimality} (Section~\ref{sec:lwd}): Nominal-tag observers achieve the unique Pareto-optimal point in the $(L, W, D)$ tradeoff space (tag length, witness cost, distortion).

\item \textbf{Machine-Checked Proofs}: All results formalized in Lean 4 (6,086 lines, 265 theorems, 0 \texttt{sorry} placeholders).
\end{enumerate}

\subsection{Related Work and Positioning}

\textbf{Identification via channels.} Our work extends the identification paradigm introduced by Ahlswede and Dueck \cite{ahlswede1989identification, ahlswede1989identification2}. In their framework, a decoder need not reconstruct a message but only answer ``is the message $m$?'' for a given hypothesis. This yields dramatically different capacity---double-exponential codebook sizes become achievable. Our setting differs in three ways: (1) we consider zero-error identification rather than vanishing error, (2) queries are adaptive rather than block codes, and (3) we allow auxiliary tagging (rate $L$) to reduce query cost. The $(L, W, D)$ tradeoff generalizes Ahlswede-Dueck to a multi-dimensional operating regime.

\textbf{Rate-distortion theory.} The $(L, W, D)$ framework connects to Shannon's rate-distortion theory \cite{shannon1959coding, berger1971rate} with an important twist: the ``distortion'' $D$ is semantic (class misidentification), and there is a second resource $W$ (query cost) alongside rate $L$. Classical rate-distortion asks: what is the minimum rate to achieve distortion $D$? We ask: given rate $L$, what is the minimum query cost $W$ to achieve distortion $D = 0$? The Pareto frontier (Theorem~\ref{thm:lwd-optimal}) characterizes this three-dimensional tradeoff. Recent work on rate-distortion-perception tradeoffs \cite{blau2019rethinking} similarly extends classical RD theory to multiple objectives; our query-cost dimension $W$ plays an analogous role to their perception constraint.

\textbf{Zero-error information theory.} The matroid structure (Section~\ref{sec:matroid}) connects to zero-error capacity and graph entropy. K\"orner \cite{korner1973coding} and Witsenhausen \cite{witsenhausen1976zero} studied zero-error source coding where confusable symbols must be distinguished. Our distinguishing dimension (Definition~\ref{def:distinguishing-dimension}) is the minimum number of binary queries to separate all classes---precisely the zero-error identification cost when $L = 0$.

\textbf{Query complexity and communication complexity.} The $\Omega(n)$ lower bound for interface-only identification relates to decision tree complexity \cite{buhrman2002complexity} and interactive communication \cite{orlitsky1991worst}. The key distinction is that our queries are constrained to a fixed attribute family $\mathcal{I}$, not arbitrary predicates. This constraint models practical systems where the observer's interface to entities is architecturally fixed.

\textbf{Compression in classification systems.} Our framework instantiates to type systems, where the compression question becomes: how many bits must be stored per object to enable $O(1)$ type identification? The answer---$\lceil \log_2 k \rceil$ bits for $k$ classes---matches the converse bound (Theorem~\ref{thm:converse}). This provides an information-theoretic foundation for the nominal-vs-structural typing debate in programming language theory \cite{Cardelli1985, cook1990inheritance}.

\textbf{Historical context.} The ``duck typing'' philosophy (``if it walks like a duck and quacks like a duck, it's a duck'') advocates structural observation over nominal tagging. Within our model, we prove this incurs $\Omega(n)$ witness cost where tagging achieves $O(1)$. The result does not ``resolve'' the broader debate---which involves usability and tooling concerns beyond this model---but establishes that the tradeoff has a precise information-theoretic component.

\textbf{Practical convergence.} Modern systems have converged on hybrid classification: Python's Abstract Base Classes, TypeScript's branded types, Rust's trait system, DNA barcoding in taxonomy \cite{DNABarcoding}. This convergence is consistent with the rate-query tradeoff: nominal tags provide $O(1)$ identification at cost $O(\log k)$ bits. The contribution is not advocacy for any design, but a formal framework for analyzing identification cost in classification systems.

\subsection{Paper Organization}

Section~\ref{sec:framework} formalizes the compression framework and defines the $(L, W, D)$ tradeoff. Section~\ref{sec:complexity} establishes complexity bounds for error localization. Section~\ref{sec:matroid} proves the matroid structure of type axes. Section~\ref{sec:witness} analyzes witness cost in detail. Section~\ref{sec:lwd} proves Pareto optimality. Section~\ref{sec:applications} instantiates the theory in real runtimes. Section~\ref{sec:conclusion} concludes. Appendix~\ref{sec:lean} describes the Lean 4 formalization.

