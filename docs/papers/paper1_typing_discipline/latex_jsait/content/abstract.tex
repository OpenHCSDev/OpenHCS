\begin{abstract}
Classification systems---database schemas, biological taxonomies, type systems, knowledge graphs---must answer queries about entities using a fixed set of observable attributes. We prove fundamental limits on what such systems can compute.

\textbf{Impossibility.} An observer limited to attribute-membership queries cannot determine entity identity when distinct entities share identical attribute profiles. This is an information barrier, not a computational limitation: no algorithm can extract information the observations do not contain.

\textbf{Optimality.} A single additional primitive---a nominal tag identifying each entity's class---reduces witness cost from $\Omega(n)$ to $O(1)$. We prove this is Pareto-optimal in the $(L, W, D)$ tradeoff space (tag length, witness cost, semantic distortion). The optimality is \emph{unique}: no other observation strategy achieves $D = 0$ with lower witness cost.

\textbf{Structure.} Minimal distinguishing query sets form the bases of a matroid. All such sets have equal cardinality; the ``distinguishing dimension'' of a classification problem is well-defined and computable.

\textbf{Significance.} Classification system design is not a matter of preference---it has information-theoretic consequences. Attribute-only observation incurs unavoidable costs that nominal tagging eliminates. The witness-cost gap is unbounded: $\Omega(n)$ for duck typing versus $O(1)$ for nominal tagging. This explains why programming languages have converged on hybrid systems (Python's ABCs, TypeScript's brands, Rust's traits), and provides design principles for classification systems in databases, taxonomy, and knowledge representation.

All results are machine-checked in Lean 4 (6,000+ lines, 0 \texttt{sorry}).

\textbf{Keywords:} classification theory, information barriers, witness complexity, matroid structure, formal verification
\end{abstract}

