\appendix

\section{Completeness and Robustness Analysis}\label{appendix:robustness}

This appendix provides detailed analysis addressing potential concerns
about the scope, applicability, and completeness of our results.

\subsection{Comprehensive Concern Analysis}\label{appendix:concerns}

We identify the major categories of potential concerns and demonstrate
why each does not affect our conclusions.

\small
\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5143}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4857}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Potential Concern
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Formal Analysis
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
``Model is incomplete'' & Theorem 3.32 (Model Completeness) \\
``Duck typing has tradeoffs'' & Theorems 3.34-3.36 (Capability Comparison) \\
``Axioms are assumptive'' & Lemma 3.37 (Axiom is Definitional) \\
``Clever extension could fix it'' & Theorem 3.39 (Extension Impossibility) \\
``What about generics?'' & Theorems 3.43-3.48, Table 2.2 (Parameterized N) \\
``Erasure changes things'' & Theorems 3.46-3.47 (Compile-Time Type Checking) \\
``Only works for some languages'' & Theorem 3.47 (8 languages), Remark 3.49 (exotic features) \\
``What about intersection/union types?'' & Remark 3.49 (still two axes) \\
``What about row polymorphism?'' & Remark 3.49 (pure S, loses capabilities) \\
``What about higher-kinded types?'' & Remark 3.49 (parameterized N) \\
``Only applies to greenfield'' & Theorem 2.10j (Adapters eliminate retrofit exception) \\
``Legacy codebases are different'' & Corollary 3.51 (sacrifice, not alternative) \\
``Claims are too broad'' & Theorem 2.6 (axis requirements are domain-derived) \\
``Dominance $\neq$ migration'' & Theorem 3.55 (Dominance $\neq$ Migration) \\
``Greenfield is undefined'' & Definitions 3.57-3.58, Theorem 3.59 \\
``Provenance requirement is circular'' & Theorem 3.61 (Provenance Detection) \\
``You just need discipline'' & Concern 8: Discipline is the external oracle \\
``The proofs are trivial'' & Concern 9: Definitional proofs from correct modeling \\
``Java/Rust can do this too'' & Concern 10: Enable vs enforce distinction \\
``This is just subtyping'' & Concern 11: Construction vs relationship (orthogonal layers) \\
\end{longtable}
\normalsize

\subsection{Detailed Analysis of Each Concern}\label{appendix:detailed-concerns}

We expand the most common concerns below; the remaining items in the table
above are direct corollaries of the referenced results.

\paragraph{Concern 1: Model Completeness.}
\emph{Potential concern:} The (B, S) model may fail to capture relevant
aspects of type systems.

\emph{Analysis:} Theorem~\ref{thm:model-completeness} establishes model completeness by constitutive
definition. In Python, \texttt{type(name, bases, namespace)} is the universal
type constructor. A type does not merely \emph{have} $(B, S)$; a type
\emph{is} $(B, S)$. Any computable function over types is therefore
definitionally a function of this triple. Properties like \texttt{\_\_mro\_\_}
or \texttt{\_\_module\_\_} are not counterexamples: they are derived from or
stored within $(B, S)$. This is definitional closure, not empirical
enumeration. No ``fourth axis'' can exist because the triple is constitutive.

\paragraph{Concern 2: Duck Typing Tradeoffs.}
\emph{Potential concern:} Duck typing has flexibility that nominal typing lacks.

\emph{Analysis:} Theorems 3.34-3.36 establish that nominal typing provides a
strict superset of duck typing capabilities. Duck typing's ``acceptance'' of
structurally-equivalent types is not a capability: it is the \emph{absence}
of the capability to distinguish them. We treat ``capability'' as the set of
definable operations/predicates available to the system, not the cost of
retrofitting legacy code; migration/retrofit cost is handled separately
(Theorem~\ref{thm:dominance-not-migration}, adapter results in Theorem~\ref{thm:protocol-strictly-dominated}).

\paragraph{Concern 3: Axiom Circularity.}
\emph{Potential concern:} The axioms are chosen to guarantee the conclusion.

\emph{Analysis:} Lemma~\ref{lem:shape-axiom-definitional} establishes that the axiom ``shape-based typing treats
same-namespace types identically'' is not an assumption: it is the
\emph{definition} of shape-based typing (Definition 2.10).

\paragraph{Concern 4: Future Extensions.}
\emph{Potential concern:} A clever extension to duck typing could recover provenance.

\emph{Analysis:} Theorem~\ref{thm:extension-impossibility} proves that any computable extension over $\{S\}$
(even with the leaf of $B$, i.e., type names) cannot recover provenance. The limitation is structural, not technical.
A common response is ``just check \texttt{type(x)}'', but this proves the point:
inspecting \texttt{type(x)} gives you the leaf of $B$. To get provenance, you need the full lineage.
Once you consult the full $B$ axis, you have left shape-only typing and moved to
nominal typing. The ``fix'' is the adoption of our thesis.

\paragraph{Concern 5: Generics and Parametric Polymorphism.}
\emph{Potential concern:} The model doesn't handle generics.

\emph{Analysis:} Theorems 3.43-3.48 establish that generics preserve the axis
structure. Type parameters are a refinement of N, not additional information
orthogonal to $(B, S)$.

\paragraph{Concern 6: Single Codebase Evidence.}
\emph{Potential concern:} Evidence is from one codebase (OpenHCS).

\emph{Analysis:} This objection conflates \textbf{existential witnesses} with
\textbf{premises}. A category error. In logic, a premise is something the
conclusion depends on; an existential witness demonstrates satisfiability.

The dominance theorems are proven from the \emph{definition} of shape-based
typing (Lemma~\ref{lem:shape-axiom-definitional}: the axiom is definitional). Examine the proof of Theorem~\ref{thm:provenance-impossibility} (Provenance Impossibility): it proceeds by showing that $(S)$ contains
insufficient information to compute provenance. This is an
information-theoretic argument that references no codebase. You could prove
this theorem before any codebase existed.

OpenHCS appears only to demonstrate that the four capabilities are
\emph{achievable}. That a real system uses provenance, identity, enumeration,
and conflict resolution. This is an existence proof (``such systems exist''),
not a premise (``if OpenHCS works, then the theorems hold'').

\textbf{Analogy:} Proving ``comparison-based sorting requires $\Omega(n \log n)$
comparisons'' does not require testing on multiple arrays. The proof is
structural. Exhibiting quicksort demonstrates the bound is achievable, not that
the theorem is true. Similarly, our theorems follow from (B, S) structure;
OpenHCS demonstrates achievability.

\paragraph{Concern 7: Scope Confusion.}
\emph{Potential concern:} Discipline dominance implies migration recommendation.

\emph{Analysis:} Theorem~\ref{thm:dominance-not-migration} formally proves that Pareto dominance of discipline
A over B does NOT imply that migrating from B to A is beneficial for all
codebases. Dominance is codebase-independent; migration cost is codebase-dependent.

\paragraph{Concern 8: You Just Need Discipline.}
\emph{Potential concern:} Real teams maintain consistency through code review, documentation, and discipline. Language features are unnecessary.

\emph{Analysis:} Discipline \emph{is} the external oracle. When multiple locations encode the same fact (DOF $> 1$), consistency requires an oracle to resolve disagreements. ``Code review and documentation'' are exactly that oracle---human-maintained, fallible, bypassable.

The question is whether the oracle is:
\begin{itemize}
\tightlist
\item \textbf{Internal} (language-enforced, automatic, unforgeable), or
\item \textbf{External} (human-maintained, fallible, bypassable)
\end{itemize}

Nominal typing with Python's \texttt{\_\_subclasses\_\_()} provides an internal oracle: the language guarantees the registry is complete. Duck typing requires an external oracle: humans must remember to update all locations. Both achieve consistency when they work. The difference is failure mode: language enforcement cannot be forgotten; human discipline can.

This is not a counterargument to our thesis; it is the thesis restated. We prove that systems without nominal typing require external oracles.

\paragraph{Concern 9: The Proofs Are Trivial.}
\emph{Potential concern:} Most proofs are just \texttt{rfl} (reflexivity). They're trivial tautologies, not real theorems.

\emph{Analysis:} When modeling is correct, theorems become definitional. This is a feature, not a bug.

Consider: ``The sum of two even numbers is even.'' In a well-designed formalization, this might be \texttt{rfl}---not because it's trivial, but because the definition of ``even'' makes the property structural.

Not all proofs are \texttt{rfl}. The \texttt{provenance\_impossibility} theorem requires 40+ lines:
\begin{enumerate}
\tightlist
\item Assume a hypothetical provenance function exists for $\{S\}$-only systems
\item Construct two types with identical S but different B (different lineages)
\item Show the function must return different values for indistinguishable inputs
\item Contradiction
\end{enumerate}

The proof structure (assumption → construction → contradiction) is genuine mathematical reasoning. The \texttt{rfl} proofs establish scaffolding; substantive proofs build on that scaffolding.

\paragraph{Concern 10: Static Languages Achieve This With Reflection/Macros.}
\emph{Potential concern:} Java has reflection. Rust has proc macros. These languages can achieve the same capabilities.

\emph{Analysis:} Reflection and macros enable \emph{patterns} but do not \emph{enforce} them. The critical distinction:

\textbf{Java reflection:} You can query \texttt{Class.getDeclaredMethods()} at runtime, but:
\begin{itemize}
\tightlist
\item No automatic hook fires when a class is defined
\item You must manually maintain registries (DOF $\geq$ 2)
\item The pattern is bypassable: create a class without registering it
\end{itemize}

\textbf{Rust proc macros:} You can generate code at compile time, but:
\begin{itemize}
\tightlist
\item Macros are per-item isolated---they cannot see other items during expansion
\item Registration is bypassable: \texttt{impl Trait} without \texttt{\#[derive]} annotation
\item The \texttt{inventory} crate uses linker tricks external to language semantics
\end{itemize}

Contrast Python:
\begin{verbatim}
class Handler(Registry):  # __init_subclass__ fires AUTOMATICALLY
    pass  # Cannot create unregistered subclass---IMPOSSIBLE
\end{verbatim}

Python's hook is \emph{unforgeable}. The language semantics guarantee that creating a subclass triggers the hook. There is no syntax to bypass this.

The objection confuses ``can create a registry'' with ``can guarantee all items are in the registry.'' Static languages enable the former; Python enforces the latter. This is the difference between DOF $\geq$ 2 and DOF = 1.

\paragraph{Concern 11: This Is Just Subtyping.}
\emph{Potential concern:} The axis-parametric proposal ($T(\text{scope}=X)$ vs $T(\text{scope}=Y)$) is really about subtyping, and the author is confused about basic type theory.

\emph{Analysis:} This objection conflates two orthogonal concerns:

\begin{enumerate}
\item \textbf{Type construction} (our claim): How is a type's \emph{identity} determined at creation time?
\item \textbf{Subtyping} (not our claim): Given two types, can one substitute for the other?
\end{enumerate}

\textbf{Subtyping} answers: ``Can I use type $A$ where type $B$ is expected?'' This presupposes types $A$ and $B$ already exist. It concerns \emph{relationships between types}: $A <: B$, covariance, contravariance, Liskov substitution.

\textbf{Axis-parametric construction} answers: ``What \emph{is} this type?'' It concerns type \emph{identity} at creation time. Our proposal extends \texttt{type(name, bases, namespace)} to \texttt{type(name, bases, namespace, **axes)}, where axes become part of the type's identity. $T(\text{scope}=X)$ and $T(\text{scope}=Y)$ are simply \emph{different types}---not subtypes, not supertypes, just distinct.

\textbf{The category error:} Responding to ``type constructors should accept semantic axes'' with ``you're confused about subtyping'' is like responding to ``cars should have different engine options'' with ``you're confused about traffic laws.'' Construction and relationship are different layers.

\textbf{Where subtyping \emph{could} enter:} One might later ask: ``Is $T(\text{scope}=X) <: T(\text{scope}=Y)$?'' This is a valid question---but it comes \emph{after} our proposal, not instead of it. We make no claims about subtype relationships between axis-instantiated types. The axes determine identity; subtyping relationships are a separate design choice.

\textbf{The pattern-match failure:} The objection likely arises from pattern-matching ``type parameters'' $\rightarrow$ ``must be about variance/subtyping.'' But type parameters in generics (e.g., \texttt{List[T]}) are indeed subject to variance analysis. Semantic axes are not type parameters in this sense---they are construction-time metadata that become part of type identity, analogous to how \texttt{bases} in \texttt{type(name, bases, ns)} determines identity without being ``about subtyping.''

\subsection{Formal Verification Status}\label{appendix:verification}

All core theorems are machine-checked in Lean 4:

\begin{itemize}
\tightlist
\item 6300+ lines of Lean code
\item 190+ theorems verified
\item 0 \texttt{sorry} placeholders
\item 0 axioms beyond standard Lean foundations (\texttt{propext}, \texttt{Quot.sound}, \texttt{Classical.choice} only)
\end{itemize}

The Lean formalization is publicly available for verification.

\section{Historical and Methodological Context}\label{appendix:historical}

\subsection{On the Treatment of Defaults}\label{appendix:defaults}

Duck typing was accepted as ``Pythonic'' without formal justification.
This asymmetry (conventions often require no proof, while changing
conventions demands proof) is a methodological observation about
community standards, not a logical requirement. The theorems in this
paper provide the formal foundation that was absent from the original
adoption of duck typing as a default.

\subsection{Why Formal Treatment Was Delayed}\label{appendix:delay}

Prior work established qualitative foundations (Malayeri \& Aldrich 2008, 2009;
Abdelgawad \& Cartwright 2014; Abdelgawad 2016). We provide the first
machine-verified formal treatment of typing discipline selection.

