\section{Related Work}\label{sec:related}

\subsection{Computational Decision Theory}

The complexity of decision-making has been studied extensively. Papadimitriou~\cite{papadimitriou1994complexity} established foundational results on the complexity of game-theoretic solution concepts. Our work extends this to the meta-question of identifying relevant information. For a modern treatment of complexity classes, see Arora and Barak \cite{arora2009computational}.

\paragraph{Closest prior work and novelty.}
Closest to our contribution is the feature-selection/model-selection hardness literature, which proves NP-hardness and inapproximability for predictive subset selection~\cite{blum1997selection, amaldi1998complexity}. Our contribution is stronger on two axes those works do not provide: (i) machine-checked reductions (TAUTOLOGY and $\exists\forall$-SAT mappings with explicit polynomial bounds), and (ii) a complete hardness/tractability landscape for decision relevance under explicit encoding assumptions. We study decision relevance rather than predictive compression, and we formalize the core reductions in Lean 4 rather than leaving them only on paper.

\subsection{Feature Selection}

In machine learning, feature selection asks which input features are relevant for prediction. This is known to be NP-hard in general~\cite{blum1997selection}. Our results show the decision-theoretic analog is \coNP-complete for both checking and minimization.

\subsection{Value of Information}

The value of information (VOI) framework~\cite{howard1966information} quantifies the maximum rational payment for information. Our work addresses a different question: not the \emph{value} of information, but the \emph{complexity} of identifying which information has value.

\subsection{Model Selection}

Statistical model selection (AIC \cite{akaike1974new}, BIC \cite{schwarz1978estimating}, cross-validation \cite{stone1974cross}) provides practical heuristics for choosing among models. Our results formalize the regime-level reason heuristic selection appears: without added structural assumptions, exact optimal model selection inherits worst-case intractability, so heuristic methods implement explicit weakened-guarantee policies for unresolved structure.

\subsection{Certifying Outputs and Proof-Carrying Claims}

Our integrity layer matches the certifying-algorithms pattern: algorithms emit candidate outputs together with certificates that can be checked quickly, separating \emph{producing} claims from \emph{verifying} claims \cite{mcconnell2010certifying}. In this paper, Definition~\ref{def:solver-integrity} is exactly that soundness discipline.

At the systems level, this is the same architecture as proof-carrying code: a producer ships evidence and a consumer runs a small checker before accepting the claim \cite{necula1997proof}. Our competence definition adds the regime-specific coverage/resource requirement that certifying soundness alone does not provide.

The feasibility qualifier in Definition~\ref{def:competence-regime} also aligns with bounded-rationality normativity: what agents \emph{should} do is constrained by what is computationally feasible under the declared resource model \cite{sep_bounded_rationality}.
