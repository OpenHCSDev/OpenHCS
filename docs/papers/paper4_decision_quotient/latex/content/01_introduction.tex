\section{Introduction}\label{sec:introduction}

This paper establishes a fundamental limit on rational decision-making under uncertainty:

\begin{quote}
\textbf{Determining what you need to know is harder than knowing everything.}
\end{quote}

This is not metaphor. It is a theorem. Specifically: given a decision problem with $n$ dimensions of uncertainty, \emph{checking} whether a subset of dimensions suffices for optimal action is \coNP-complete. \emph{Finding} the minimal sufficient subset is \coNP-complete. These results hold universally---for any decision problem with coordinate structure.

The implications are immediate and far-reaching. Engineers who include ``irrelevant'' information in their models are not exhibiting poor discipline. They are responding optimally to a computational constraint that admits no workaround. Climate scientists modeling atmospheric chemistry, financial analysts tracking hundreds of indicators, software architects specifying dozens of parameters---all are exhibiting computationally rational behavior. The alternative (identifying precisely which variables matter) requires solving \coNP-complete problems.

\subsection{The Core Problem}

Consider a decision problem with actions $A$ and states $S = X_1 \times \cdots \times X_n$ (a product of $n$ coordinate spaces). For each state $s \in S$, some subset $\Opt(s) \subseteq A$ of actions are optimal. The fundamental question is:

\begin{quote}
\textbf{Which coordinates are sufficient to determine the optimal action?}
\end{quote}

A coordinate set $I \subseteq \{1, \ldots, n\}$ is \emph{sufficient} if knowing only the coordinates in $I$ determines the optimal action set:
\[
s_I = s'_I \implies \Opt(s) = \Opt(s')
\]
where $s_I$ denotes the projection of state $s$ onto coordinates in $I$.

\subsection{Main Results}

This paper proves four main theorems:

\begin{enumerate}
\item \textbf{Theorem~\ref{thm:sufficiency-conp} (Sufficiency Checking is \coNP-complete):} Given a decision problem and coordinate set $I$, determining whether $I$ is sufficient is \coNP-complete \cite{cook1971complexity, karp1972reducibility}.

\item \textbf{Theorem~\ref{thm:minsuff-conp} (Minimum Sufficiency is \coNP-complete):} Finding the minimum sufficient coordinate set is \coNP-complete. (The problem is trivially in $\SigmaP{2}$ by structure, but collapses to \coNP{} because sufficiency equals ``superset of relevant coordinates.'')

\item \textbf{Theorem~\ref{thm:dichotomy} (Complexity Dichotomy):} Sufficiency checking exhibits a dichotomy:
\begin{itemize}
\item If the minimal sufficient set has size $O(\log |S|)$, checking is polynomial
\item If the minimal sufficient set has size $\Omega(n)$, checking requires exponential time \cite{impagliazzo2001complexity}.
\end{itemize}

\item \textbf{Theorem~\ref{thm:tractable} (Tractable Subcases):} Sufficiency checking is polynomial-time for:
\begin{itemize}
\item Bounded action sets ($|A| \leq k$ for constant $k$)
\item Separable utility functions ($u(a,s) = f(a) + g(s)$)
\item Tree-structured coordinate dependencies
\end{itemize}
\end{enumerate}

\subsection{The Foundational Principle}

The core result transcends the specific application domain:

\begin{quote}
\textbf{For any agent facing structured uncertainty, identifying the relevant dimensions of uncertainty is computationally harder than simply observing all dimensions.}
\end{quote}

This applies to:
\begin{itemize}
\item \textbf{Machine learning:} Feature selection is intractable in general
\item \textbf{Economics:} Identifying relevant market factors is intractable
\item \textbf{Scientific modeling:} Determining which variables matter is intractable
\item \textbf{Software engineering:} Configuration minimization is intractable
\end{itemize}

The ubiquity of over-modeling, over-parameterization, and ``include everything'' strategies across domains is not coincidence. It is the universal rational response to a universal computational constraint.

\subsection{Connection to Prior Papers}

This paper completes the theoretical foundation established in Papers 1--3:

\begin{itemize}
\item \textbf{Paper 1 (Typing):} Showed nominal typing dominates structural typing
\item \textbf{Paper 2 (SSOT):} Showed single source of truth minimizes modification complexity
\item \textbf{Paper 3 (Leverage):} Unified both as leverage maximization
\end{itemize}

\textbf{Paper 4's contribution:} Proves that \emph{identifying} which architectural decisions matter is itself computationally hard. This explains why leverage maximization (Paper 3) uses heuristics rather than optimal algorithms---and why this is not a deficiency but a mathematical necessity.

\subsection{Paper Structure}

Section~\ref{sec:foundations} establishes formal foundations: decision problems, coordinate spaces, sufficiency. Section~\ref{sec:hardness} proves hardness results with complete reductions. Section~\ref{sec:dichotomy} develops the complexity dichotomy. Section~\ref{sec:tractable} presents tractable special cases. Section~\ref{sec:implications} discusses implications for software architecture and modeling. Section~\ref{sec:related} surveys related work. Appendix~\ref{app:lean} contains Lean proof listings. Appendix~\ref{appendix-rebuttals} addresses anticipated objections.

\subsection{Anticipated Objections}\label{sec:objection-summary}

Before proceeding, we address objections readers are likely forming. Each is refuted in detail in Appendix~\ref{appendix-rebuttals}; here we summarize the key points.

\paragraph{``coNP-completeness doesn't mean intractable---there might be good heuristics.''}
Correct, but this strengthens our thesis. The point is not that practitioners cannot find useful approximations, but that \emph{optimal} dimension selection is provably hard. The prevalence of heuristics (feature selection in ML, sensitivity analysis in economics) is itself evidence of the computational barrier.

\paragraph{``Real decision problems don't have clean coordinate structure.''}
The coordinate structure assumption is weaker than it appears. Any finite state space can be encoded with binary coordinates; the hardness results apply to this encoding. More structured representations make the problem \emph{easier}, not harder---so hardness for structured problems implies hardness for general ones.

\paragraph{``The reduction from SAT is artificial.''}
All \coNP-completeness proofs use reductions. The reduction demonstrates that SAT instances can be encoded as sufficiency-checking problems while preserving computational structure. This is standard complexity theory methodology \cite{cook1971complexity, karp1972reducibility}. The claim is not that practitioners encounter SAT problems, but that sufficiency checking is at least as hard as SAT.

\paragraph{``The tractable subcases are too restrictive to be useful.''}
The tractable subcases (bounded actions, separable utility, tree structure) characterize \emph{when} dimension selection becomes feasible. Many real problems fall into these categories. The dichotomy theorem (Theorem~\ref{thm:dichotomy}) precisely identifies the boundary between tractable and intractable.

\paragraph{``This just formalizes the obvious---of course feature selection is hard.''}
The contribution is making ``obvious'' precise. Prior work established heuristic hardness for specific domains (ML feature selection, economic factor identification). We prove a \emph{universal} result that applies to \emph{any} decision problem with coordinate structure. This unification is the theoretical contribution.

\medskip
\noindent\textbf{If you have an objection not listed above,} check Appendix~\ref{appendix-rebuttals} (8 objections addressed) before concluding it has not been considered.

