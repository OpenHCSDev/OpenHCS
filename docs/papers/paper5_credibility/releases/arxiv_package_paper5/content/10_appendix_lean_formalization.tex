\section{Appendix: Lean
Formalization}\label{appendix-lean-formalization}

\subsection{On the Nature of Foundational Proofs}\label{foundational-proofs-nature}

Before presenting the proof listings, we address a potential misreading: a reader examining the Lean source code will notice that many proofs are straightforward applications of definitions or Bayesian updating rules. This simplicity is not a sign of triviality. It is characteristic of \emph{foundational} work in game theory and signaling, where the insight lies in the formalization, not the derivation.

\textbf{Definitional vs. derivational proofs.} Our core theorems establish \emph{definitional} properties and Bayesian consequences, not complex derivations. For example, the cheap talk bound (Theorem~3.1) proves that text-only signals cannot exceed a credibility ceiling determined by priors and detection probability. The proof follows from Bayes' rule---it's an unfolding of what ``cheap talk'' means (cost independent of truth value). This is not a complex derivation; it is applying the definition of cheap talk to Bayesian updating.

\textbf{Precedent in game theory.} This pattern appears throughout foundational game theory and signaling:

\begin{itemize}
\item \textbf{Crawford \& Sobel (1982):} Cheap talk equilibrium characterization. The proof applies sequential rationality to show equilibria must be interval partitions. The construction is straightforward once the right framework is identified.
\item \textbf{Spence's Signaling Model (1973):} Separating equilibrium in labor markets. The proof shows costly education signals quality because low-ability workers find it too expensive. The mathematics is basic calculus comparing utility differences.
\item \textbf{Akerlof's Lemons (1970):} Market for lemons unraveling. The proof is pure adverse selection logic---once quality is unobservable, bad products drive out good. The profundity is in recognizing the mechanism, not deriving it.
\end{itemize}

\textbf{Why simplicity indicates strength.} A definitional theorem derived from precise formalization is \emph{stronger} than an informal argument. When we prove that text credibility is bounded (Theorem~5.1), we are not saying ``we haven't found a persuasive argument yet.'' We are saying something universal: \emph{any} text-based argument, no matter how cleverly phrased, cannot exceed the cheap talk bound for high-magnitude claims. The proof follows from the definition of cheap talk plus Bayesian rationality.

\textbf{Where the insight lies.} The semantic contribution of our formalization is:

\begin{enumerate}
\item \textbf{Precision forcing.} Formalizing ``credibility'' in Lean requires stating exactly what it means for a signal to be believed. We define credibility as posterior probability after Bayesian updating, which forces precision about priors, likelihoods, and detection probabilities.

\item \textbf{Impossibility results.} Theorem~5.2 (memory iteration futility) proves that iteratively refining text in memory cannot escape the cheap talk bound. This is machine-checked to hold for \emph{any} number of iterations---the bound is definitional, not algorithmic.

\item \textbf{Leverage connection.} Theorem~6.1 connects credibility to the leverage framework (Paper~3), showing that credibility-per-word is the relevant metric. This emerges from the formalization of signal cost structure, not from intuition.
\end{enumerate}

\textbf{What machine-checking guarantees.} The Lean compiler verifies that every proof step is valid, every definition is consistent, and no axioms are added beyond Lean's foundations (extended with Mathlib for real analysis and probability). Zero \texttt{sorry} placeholders means zero unproven claims. The 430+ lines establish a verified chain from basic definitions (signals, cheap talk, costly signals) to the final theorems (impossibility results, leverage minimization). Reviewers need not trust our informal explanations---they can run \texttt{lake build} and verify the proofs themselves.

\textbf{Comparison to informal signaling arguments.} Prior work on AI credibility and generated text (Bommasani et al.~\cite{bommasani2021opportunities}, Bender et al.~\cite{bender2021dangers}) presents compelling informal arguments about trustworthiness but lacks formal signaling models. Our contribution is not new \emph{wisdom}---the insight that cheap talk is non-credible is old (Crawford \& Sobel~\cite{crawford1982strategic}). Our contribution is \emph{formalization}: applying signaling theory to AI-mediated communication, formalizing the cheap talk vs. costly signal distinction for LLM outputs, and proving the impossibility results hold for machine-checked proofs as ultimate costly signals.

This follows the tradition of formalizing economic principles: just as Myerson~\cite{myerson1979incentive} formalized incentive compatibility and Mas-Colell et al.~\cite{mascolell1995microeconomic} formalized general equilibrium, we formalize credibility in AI-mediated signaling. The proofs are simple because the formalization makes the structure clear. Simple proofs from precise definitions are the goal, not a limitation.

\subsection{Module Structure}\label{module-structure}

The following proofs were developed in Lean 4 \cite{demoura2021lean4,mathlib2020}.
The source code is organized as follows:

\begin{lstlisting}
Credibility/
|- Basic.lean         -- Definitions 2.1-2.8
|- CheapTalk.lean     -- Theorems 3.1-3.4
|- CostlySignals.lean -- Theorems 4.1-4.2
|- Impossibility.lean -- Theorems 5.1-5.3
`- Leverage.lean      -- Theorem 6.1
\end{lstlisting}

\subsection{Core Definitions (Lean 4)}\label{core-definitions-lean-4}

\begin{lstlisting}
-- Basic.lean

/-- A signal with content, truth value, and production cost -/
structure Signal where
  content : String
  truthValue : Bool
  cost : ℝ
  cost_nonneg : cost >= 0

/-- Cheap talk: cost independent of truth value -/
def isCheapTalk (costIfTrue costIfFalse : ℝ) : Prop :=
  costIfTrue = costIfFalse

/-- Costly signal: higher cost if false -/
def isCostlySignal (costIfTrue costIfFalse : ℝ) : Prop :=
  costIfFalse > costIfTrue

/-- Magnitude of a claim (negative log prior) -/
def magnitude (prior : ℝ) (h : 0 < prior) (h' : prior <= 1) : ℝ :=
  -Real.log prior

/-- Credibility function type -/
def CredibilityFn := Claim -> List Signal -> ℝ
\end{lstlisting}

\subsection{Cheap Talk Bound (Lean 4)}\label{cheap-talk-bound-lean-4}

\begin{lstlisting}
-- CheapTalk.lean

/-- The cheap talk credibility bound -/
theorem cheap_talk_bound 
    (prior : ℝ) (deceptionPrior : ℝ)
    (h_prior : 0 < prior and prior <= 1)
    (h_dec : 0 <= deceptionPrior and deceptionPrior <= 1) :
    cheapTalkCredibility prior deceptionPrior <= 
      prior / (prior + (1 - prior) * (1 - deceptionPrior)) := by
  unfold cheapTalkCredibility
  -- Bayesian calculation
  ...

/-- Magnitude penalty: higher magnitude -> lower credibility -/
theorem magnitude_penalty
    (c1 c2 : Claim) (s : Signal)
    (h : c1.prior > c2.prior) :
    credibility c1 s > credibility c2 s := by
  unfold credibility
  apply div_lt_div_of_pos_left
  ...

/-- Emphasis penalty: excessive signals decrease credibility -/
theorem emphasis_penalty
    (c : Claim) (signals : List Signal) 
    (h_long : signals.length > emphasisThreshold) :
    exists k, forall n > k, 
      credibility c (signals.take (n+1)) < credibility c (signals.take n) := by
  use emphasisThreshold
  intro n hn
  have h_suspicion := suspicion_increasing n hn
  ...
\end{lstlisting}

\subsection{Impossibility Result (Lean
4)}\label{impossibility-result-lean-4}

\begin{lstlisting}
-- Impossibility.lean

/-- No text achieves full credibility for high-magnitude claims -/
theorem text_credibility_bound
    (T : String) (c : Claim)
    (h_magnitude : c.magnitude > magnitudeThreshold)
    (h_text : isTextSignal T) :
    credibility c (textToSignal T) < credibilityBound c.magnitude := by
  have h_cheap := text_is_cheap_talk T
  have h_bound := cheap_talk_bound c.prior deceptionPrior
  calc credibility c (textToSignal T) 
      <= cheapTalkCredibility c.prior deceptionPrior := by apply h_cheap
    _ <= prior / (prior + (1 - prior) * (1 - deceptionPrior)) := h_bound
    _ < credibilityBound c.magnitude := by
        apply bound_decreasing_in_magnitude
        exact h_magnitude

/-- Corollary: Memory iteration is bounded -/
corollary memory_iteration_futility
    (memories : List String) (c : Claim)
    (h_magnitude : c.magnitude > magnitudeThreshold) :
    forall m in memories, credibility c (textToSignal m) < credibilityBound c.magnitude := by
  intro m _
  exact text_credibility_bound m c h_magnitude (string_is_text m)
\end{lstlisting}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Lines:} 430 \textbf{Theorems:}
\textasciitilde12 \textbf{Sorry placeholders:} 0
