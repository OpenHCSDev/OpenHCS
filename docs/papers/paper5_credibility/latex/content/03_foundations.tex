\section{Foundations}\label{foundations}

\subsection{Two Credibility Domains}\label{two-credibility-domains}

This paper distinguishes two fundamentally different credibility domains that obey different dynamics:

\textbf{Definition 2.0a (Mathematical Credibility).} \emph{Mathematical credibility} $C_M$ measures the probability that a claim is logically sound. The audience is a formal verifier (proof assistant, compiler, test suite). The signal space consists of artifacts that can be mechanically checked. Mathematical credibility is binary at the limit: a proof compiles or it doesn't.

\textbf{Definition 2.0b (Social Credibility).} \emph{Social credibility} $C_S$ measures the probability that a social audience accepts a claim. The audience is human agents with priors shaped by institutional hierarchy, reputation, and group membership. The signal space consists of credentials, affiliations, endorsements, and communication patterns.

\textbf{Theorem 2.0c (Domain Independence).} Mathematical credibility and social credibility are orthogonal:
\[C_M(c, s) \not\Rightarrow C_S(c, s) \quad \text{and} \quad C_S(c, s) \not\Rightarrow C_M(c, s)\]
A signal maximizing one domain does not necessarily affect the other.

\emph{Proof.} Constructive. (1) High $C_M$, low $C_S$: a correct proof by an unknown author receives $C_M \to 1$ (it compiles) but may receive $C_S \approx P_{\text{prior}}$ (no institutional endorsement). (2) High $C_S$, low $C_M$: a claim by a prestigious institution without formal verification receives high $C_S$ (reputation transfer) but $C_M$ is undefined or low (no proof). \qed

\textbf{Corollary 2.0d (Costly Signal Domain-Specificity).} Costly signals are domain-specific:
\begin{itemize}
\item Machine-checked proofs are maximally costly in the mathematical domain (cannot compile a false proof) but may be cheap talk in the social domain (anyone can claim to have proofs).
\item Institutional credentials (PhD, tenure, affiliation) are costly in the social domain (years of compliance) but cheap talk in the mathematical domain (credential $\not\Rightarrow$ soundness).
\end{itemize}

\textbf{Remark (Credibility Domain Conflict).} When a signal achieves $C_M \to 1$ but $C_S \approx 0$, the mathematical and social domains are in conflict. A rational response in the mathematical domain (engage with proofs) differs from a rational response in the social domain (defer to hierarchy). Observers may respond in either domain. This paper's theorems apply within each domain separately; cross-domain dynamics require modeling both simultaneously.

\subsection{Dual Truth Framework}\label{dual-truth-framework}

This paper introduces a dual truth framework that distinguishes between objective validity and subjective acceptance:

\textbf{Definition 2.0e (Epistemic Truth, $E$).} \emph{Epistemic truth} measures the probability that a claim corresponds to objective reality or logical truth. It is measurable via empirical evidence, logical proof, or formal verification. Range: $E \in [0, 1]$, where $E = 1$ indicates absolute truth and $E = 0$ indicates absolute falsity. Properties: objective, verifiable, independent of observer.

\textbf{Definition 2.0f (Ego-Driven Truth, $G$).} \emph{Ego-driven truth} measures the probability that a claim aligns with an agent's self-interest, beliefs, or identity. It is measurable via incentive analysis, bias detection, or psychological modeling. Range: $G \in [0, 1]$, where $G = 1$ indicates perfect alignment and $G = 0$ indicates complete contradiction. Properties: subjective, observer-dependent, context-sensitive.

\textbf{Definition 2.0g (Truth Vector).} The \emph{truth vector} is a 2D vector:
\[
\vec{T} = (E, G) \in [0, 1]^2
\]
representing both the objective validity and subjective acceptance of a claim. This vector captures the dual nature of truth in epistemic communication.

\textbf{Theorem 2.0h (Truth Orthogonality).} Epistemic truth and ego-driven truth are orthogonal dimensions:
\[
E \perp G \quad \text{(no direct causal relationship)}
\]
A change in one dimension does not necessarily affect the other. This orthogonality is analogous to the independence of mathematical and social credibility domains.

\emph{Proof.} Constructive. (1) High $E$, low $G$: a scientifically proven fact that contradicts an agent's deeply held beliefs (e.g., climate change for a fossil fuel executive). (2) Low $E$, high $G$: a comforting lie that aligns perfectly with an agent's self-interest (e.g., "I'm a great driver" despite poor performance). \qed

\textbf{Corollary 2.0i (Truth Tradeoff).} For high-magnitude claims (low prior probability), there exists a threshold where increasing epistemic truth decreases ego-driven truth and vice versa:
\[
\exists k^* \in [0,1] : \forall E > k^* \implies \frac{\partial G}{\partial E} < 0
\]

\subsection{Signals and Costs}\label{signals-and-costs}

\textbf{Definition 2.1 (Signal).} A \emph{signal} is a tuple
\(s = (c, v, p)\) where: - \(c\) is the \emph{content} (what is
communicated) - \(v \in \{\top, \bot\}\) is the \emph{truth value}
(whether content is true) - \(p : \mathbb{R}_{\geq 0}\) is the
\emph{production cost}

\textbf{Definition 2.2 (Cheap Talk).} A signal \(s\) is \emph{cheap
talk} if production cost is truth-independent:
\[\text{Cost}(s | v = \top) = \text{Cost}(s | v = \bot)\]

\textbf{Definition 2.3 (Costly Signal).} A signal \(s\) is \emph{costly}
if: \[\text{Cost}(s | v = \bot) > \text{Cost}(s | v = \top)\] Producing
the signal when false costs more than when true.

\textbf{Intuition:} Verbal assertions are cheap talk---saying ``I'm
honest'' costs the same whether you're honest or not. A PhD from MIT is
a costly signal \cite{spence1973job}---obtaining it while incompetent is much harder than
while competent. Similarly, price and advertising can serve as signals of quality \cite{milgrom1986price}.

\subsection{Credibility Functions}\label{credibility-functions}

\textbf{Definition 2.4 (Prior).} A \emph{prior} is a probability
distribution \(P : \mathcal{C} \to [0,1]\) over claims, representing
beliefs before observing signals.

\textbf{Definition 2.5 (Credibility Function).} A \emph{credibility
function} is a mapping:
\[C : \mathcal{C} \times \mathcal{S}^* \to [0,1]\] from (claim,
signal-sequence) pairs to credibility scores, satisfying: 1.
\(C(c, \emptyset) = P(c)\) (base case: prior) 2. Bayesian update:
\(C(c, s_{1..n}) = P(c | s_{1..n})\)

\textbf{Definition 2.6 (Rational Agent).} An agent is \emph{rational}
if: 1. Updates beliefs via Bayes' rule 2. Has common knowledge of
rationality \cite{aumann1995backward} (knows others are rational, knows others know, etc.) 3.
Accounts for strategic signal production \cite{cho1987signaling}.

\subsection{Deception Model}\label{deception-model}

\textbf{Definition 2.7 (Deception Prior).} Let \(\pi_d \in [0,1]\) be
the prior probability that a random agent will produce deceptive
signals. This is common knowledge.

\textbf{Definition 2.8 (Magnitude).} The \emph{magnitude} of a claim
\(c\) is: \[M(c) = -\log P(c)\] High-magnitude claims have low prior
probability. This is the standard self-information measure \cite{shannon1948}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

