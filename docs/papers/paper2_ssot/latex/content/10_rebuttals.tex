\section{Preemptive Rebuttals}\label{sec:rebuttals}

This appendix addresses anticipated objections. Each objection is stated in its strongest form, then refuted.

\subsection{Objection: The SSOT Definition is Too Narrow}

\textbf{Objection:} ``Your definition of SSOT as DOF = 1 is too restrictive. Real-world systems have acceptable levels of duplication.''

\textbf{Response:} The definition is \textbf{derived}, not chosen. DOF = 1 is the unique optimal point:

\begin{center}
\begin{tabular}{cl}
\toprule
\textbf{DOF} & \textbf{Meaning} \\
\midrule
0 & Fact is not encoded (underspecification) \\
1 & Single source of truth (optimal) \\
$>$1 & Multiple sources can diverge (inconsistency risk) \\
\bottomrule
\end{tabular}
\end{center}

DOF = 2 means two locations can hold different values for the same fact. The \emph{possibility} of inconsistency exists. The definition is mathematical: SSOT requires DOF = 1. Systems with DOF $>$ 1 may be pragmatically acceptable but do not satisfy SSOT.

\subsection{External Tools vs Language-Level SSOT}

External tools (annotation processors, code generators, build systems) can approximate SSOT behavior. These differ from language-level SSOT in three dimensions:

\begin{enumerate}
\item \textbf{External to language semantics:} Build tools can fail, be misconfigured, or be bypassed. They operate outside the language model.

\item \textbf{No runtime verification:} The program cannot confirm that derivation occurred correctly. Python's \texttt{\_\_subclasses\_\_()} verifies registration completeness at runtime. External tools provide no runtime guarantee.

\item \textbf{Configuration-dependent:} External tools require project-specific setup. Python's \texttt{\_\_init\_subclass\_\_} works in any environment without configuration.
\end{enumerate}

The analysis characterizes SSOT \emph{within language semantics}, where DOF = 1 holds at runtime.

\subsection{Derivation Order}

The analysis proceeds from definition to language evaluation:

\begin{enumerate}
\item Define SSOT mathematically (DOF = 1)
\item Prove necessary language features (definition-time hooks + introspection)
\item Evaluate languages against derived criteria
\item Result: Python, CLOS, and Smalltalk satisfy both requirements
\end{enumerate}

Three languages satisfy the criteria. Two (CLOS, Smalltalk) are not mainstream. This validates that the requirements characterize a genuine language capability class. The requirements are derived from SSOT's definition, independent of any particular language's feature set.

\subsection{Empirical Validation}

The case studies demonstrate patterns, with publicly verifiable instances:

\begin{itemize}
\tightlist
\item PR \#44: 47 \texttt{hasattr()} checks → 1 ABC definition (verifiable via GitHub diff)
\item Three general patterns: contract enforcement, automatic registration, automatic discovery
\item Each pattern represents a mechanism, applicable to codebases exhibiting similar structure
\end{itemize}

The theoretical contribution is the formal proof. The examples demonstrate applicability.

\subsection{Asymptotic Analysis}

The complexity bounds are derived from the mechanism:

\begin{itemize}
\tightlist
\item SSOT: changing a fact requires 1 edit (the single source)
\item Non-SSOT: changing a fact requires $n$ edits (one per encoding location)
\item The ratio $n/1$ grows unbounded as $n$ increases
\end{itemize}

PR \#44 demonstrates the mechanism at $n = 47$: 47 \texttt{hasattr()} checks → 1 ABC definition. The 47$\times$ reduction is observable via GitHub diff. The gap widens as codebases grow.

\subsection{Cost-Benefit Analysis}

SSOT involves trade-offs:
\begin{itemize}
\tightlist
\item \textbf{Benefit:} Modification complexity $O(1)$ vs $\Omega(n)$
\item \textbf{Cost:} Metaprogramming complexity, potential performance overhead
\end{itemize}

The analysis characterizes what SSOT requires. The decision to use SSOT depends on codebase scale and change frequency.

\subsection{Machine-Checked Formalization}

The proofs formalize definitions precisely. Machine-checked proofs provide:

\begin{enumerate}
\item \textbf{Precision:} Lean requires every step to be explicit
\item \textbf{Verification:} Computer-checked, eliminating human error
\item \textbf{Reproducibility:} Anyone can run the proofs and verify results
\end{enumerate}

The contribution is formalization itself: converting informal principles into machine-verifiable theorems. Simple proofs from precise definitions are the goal.

\subsection{Build Tool Analysis}

External build tools shift the SSOT problem:

\begin{enumerate}
\item \textbf{DOF $\geq$ 2:} Build tool configuration becomes a second source. Let $C$ be codebase, $T$ be tool. Then $\text{DOF}(C \cup T, F) \geq 2$ because both source and config encode $F$.

\item \textbf{No runtime verification:} Generated code lacks derivation provenance. Cannot query ``was this method generated or hand-written?''

\item \textbf{Cache invalidation:} Build tools must track dependencies. Stale caches cause bugs absent from language-native derivation.

\item \textbf{Build latency:} Every edit requires build step. Language-native SSOT (Python metaclasses) executes during \texttt{import}.
\end{enumerate}

External tools reduce DOF from $n$ to $k$ where $k$ is the number of tool configurations. Since $k > 1$, SSOT (DOF = 1) is not satisfied.

Cross-language code generation (e.g., protobuf) requires external tools. The analysis characterizes single-language SSOT.

\subsection{Objection: Inconsistency Is Only in Comments}

\textbf{Objection:} ``The proofs don't formalize `inconsistency'---it only appears in comments. The heavy lifting is done by the comments, not by the formal system.''

\textbf{Response:} This critique was valid for earlier versions. We have since added \texttt{Ssot/Inconsistency.lean} (216 LOC, zero \texttt{sorry}), which formalizes inconsistency as a Lean \texttt{Prop}:

\begin{verbatim}
structure ConfigSystem where
  num_locations : Nat
  value_at : LocationId -> Value

def inconsistent (c : ConfigSystem) : Prop :=
  exists l1 l2, l1 < c.num_locations /\ l2 < c.num_locations /\
                l1 != l2 /\ c.value_at l1 != c.value_at l2
\end{verbatim}

The file proves:

\begin{enumerate}
\item \textbf{DOF $>$ 1 implies inconsistency possible:} \texttt{dof\_gt\_one\_implies\_inconsistency\_possible}---we constructively exhibit an inconsistent configuration for any $n > 1$.

\item \textbf{Guaranteed consistency requires DOF $\leq$ 1:} \texttt{consistency\_requires\_dof\_le\_one}---contrapositive of the above.

\item \textbf{DOF = 0 means the fact is not encoded:} \texttt{dof\_zero\_means\_not\_encoded}---no locations implies the system cannot represent the value.

\item \textbf{Independence formalized:} \texttt{update\_preserves\_other\_locations}---updating one location does not affect others, formalizing what ``independent'' means.

\item \textbf{Oracle necessity:} \texttt{resolution\_requires\_external\_choice}---when locations disagree, there exist valid oracles that give different resolutions. Therefore, resolving disagreement requires an external, arbitrary choice. The system itself provides no basis to prefer one value over another.
\end{enumerate}

This addresses the critique directly: inconsistency is now a formal property that Lean knows about, not a comment. The interpretation ``this models real configuration systems'' still requires mapping to reality, but every formalization eventually bottoms out in interpretation. The contribution is making assumptions \emph{explicit and attackable}, not eliminating interpretation entirely.

\subsection{Objection: What About the Type's Name?}

\textbf{Objection:} ``Your two-axis model (B, S) ignores the type's name. Isn't N (the name) a third independent axis?''

\textbf{Response:} No. N is not an independent axis---it is stored \emph{within} B. In Python, a class's name is simply \texttt{\_\_name\_\_ $\in$ \_\_dict\_\_}. More precisely:

\begin{enumerate}
\item \texttt{type(MyClass).\_\_name\_\_} returns \texttt{'MyClass'}
\item This is an attribute lookup, meaning \texttt{\_\_name\_\_} is a key in the class's namespace
\item The namespace \emph{is} the S axis (or accessible via B through the MRO)
\end{enumerate}

The Lean formalization (AbstractClassSystem.lean, lines 26--34) proves this formally:

\begin{verbatim}
CLARIFICATION ON "N" (Name):
- N is just a label for a (B, S) pair
- N contributes no observables beyond B
- Two types with identical (B, S) are indistinguishable regardless of N
- Theorem obs_eq_bs proves: (B, S) equality suffices; N adds nothing
\end{verbatim}

The operational test: given two classes with identical \texttt{\_\_bases\_\_} (B) and identical \texttt{\_\_dict\_\_} (S), can any Python code distinguish them by name alone? No---because the name \emph{is} an entry in \texttt{\_\_dict\_\_}. If two classes have the same dict, they have the same name.

This is why the model is (B, S) and not (B, S, N). N adds no independent information. The full derivation appears in Paper 1~\cite{paper1_typing_discipline}, but the key insight is: in any language with explicit inheritance, the ``name'' is either:
\begin{itemize}
\tightlist
\item An attribute (part of S), or
\item Derivable from the MRO (part of B)
\end{itemize}

In both cases, N collapses into the existing axes.

\subsection{Objection: Model Doesn't Mirror Compiler Internals}

\textbf{Objection:} ``Your Rust model (RuntimeItem, erasure) doesn't mirror rustc's actual HIR→MIR phases. You haven't modeled proc-macro hygiene, \texttt{\#[link\_section]} retention, or the actual expander traces.''

\textbf{Response:} We model \emph{observable behavior}, not compiler implementation. The claim is:

\begin{quote}
At runtime, you cannot distinguish hand-written code from macro-generated code.
\end{quote}

This is empirically testable. Challenge: produce Rust code that, at runtime, recovers whether a given struct was written by a human or expanded by a macro---without external metadata files, build logs, or source access.

The model's \texttt{RuntimeItem} having no source field is \emph{observationally accurate}: real Rust binaries contain no such field. Whether rustc internally tracks provenance during compilation is irrelevant; what matters is that this information is not preserved in the final artifact.

If the model is wrong, show the Rust code that falsifies it. The burden is on the critic to produce the counterexample.

\subsection{Objection: You Just Need Discipline}

\textbf{Objection:} ``Real teams maintain consistency through code review, documentation, and discipline. You don't need language features.''

\textbf{Response:} Discipline \emph{is} the human oracle. The theorem states:

\begin{quote}
With DOF $> 1$, consistency requires an external oracle to resolve disagreements.
\end{quote}

``Discipline'' is exactly that oracle---human memory, review processes, documentation conventions. This is not a counterargument; it is the theorem restated in different words.

The question is whether the oracle is:
\begin{itemize}
\tightlist
\item \textbf{Internal} (language-enforced, automatic, unforgeable), or
\item \textbf{External} (human-maintained, fallible, bypassable)
\end{itemize}

Language-level SSOT provides an internal oracle. Discipline provides an external one. Both satisfy consistency when they work. The difference is failure mode: language enforcement cannot be forgotten; human discipline can.

\subsection{Objection: The Proofs Are Trivial}

\textbf{Objection:} ``Most of your proofs are just \texttt{rfl} (reflexivity). That means they're trivial tautologies, not real theorems.''

\textbf{Response:} When you model correctly, theorems become definitional. This is a feature, not a bug.

Consider: ``The sum of two even numbers is even.'' In a well-designed formalization, this might be \texttt{rfl}---not because it's trivial, but because the definition of ``even'' was chosen to make the property structural.

That said, not all proofs are \texttt{rfl}. The \texttt{rust\_lacks\_introspection} theorem is 40 lines of actual reasoning:

\begin{enumerate}
\item Assume a hypothetical introspection function exists
\item Use \texttt{erasure\_destroys\_source} to show user-written and macro-expanded code produce identical \texttt{RuntimeItem}s
\item Derive that the function would need to return two different sources for the same item
\item Contradiction
\end{enumerate}

The proof structure (assumption → lemma application → contradiction) is genuine mathematical reasoning, not tautology. The \texttt{rfl} proofs establish the scaffolding; the substantive proofs build on that scaffolding.

\subsection{Objection: Real Codebases Don't Need Formal DOF}

\textbf{Objection:} ``Nobody actually needs Lean-enforced DOF guarantees. Conventions work fine in practice.''

\textbf{Response:} This is an interpretation gap, not a flaw in the proof. We prove:

\begin{quote}
IF you encode a fact in multiple locations AND require guaranteed consistency, THEN you need either DOF = 1 or an external oracle.
\end{quote}

Whether real codebases ``need'' guaranteed consistency is an engineering judgment outside the scope of formal verification. The same gap exists for:

\begin{itemize}
\tightlist
\item \textbf{CAP theorem:} Proves partition tolerance forces trade-off. Whether your system needs strong consistency is judgment.
\item \textbf{Rice's theorem:} Proves semantic properties are undecidable. Whether you need decidable analysis is judgment.
\item \textbf{Halting problem:} Proves general termination is undecidable. Whether your programs need termination guarantees is judgment.
\end{itemize}

The theorem characterizes what is \emph{logically required}. Application to specific codebases requires human interpretation. This is philosophy, not mathematics, and lies outside the proof's scope.

%==============================================================================
