\section{Related Work}\label{sec:related}
%==============================================================================

This section surveys related work across five areas: source coding under modification constraints, distributed systems consistency, computational reflection, software engineering principles, and formal methods.

\subsection{Source Coding Under Modification Constraints}\label{sec:related-source-coding}

Our work extends classical source coding to \emph{interactive encoding systems}---systems where encodings can be modified and must remain coherent across modifications. This connects to several established IT areas.

\textbf{Multi-Version Coding.} Rashmi et al.~\cite{rashmi2015multiversion} formalize consistent distributed storage where multiple versions of data must be accessible while maintaining consistency guarantees. Their framework addresses a key question: what is the storage cost of ensuring that any $c$ servers can decode the latest common version? They prove an ``inevitable price, in terms of storage cost, to ensure consistency.''

Our DOF = 1 theorem is analogous: we prove the \emph{encoding rate} cost of ensuring coherence under modification. Where multi-version coding trades storage for consistency across versions, we trade encoding rate for coherence across locations.

\textbf{Write-Once Memory Codes.} Rivest and Shamir~\cite{rivest1982wom} introduced WOM codes for storage media where bits can only transition $0 \to 1$. Despite this irreversibility constraint, clever coding achieves capacity $\log_2(t+1)$ for $t$ writes---more than the naive $1$ bit.

Our structural facts have an analogous irreversibility: once defined, structure is fixed. The parallel:
\begin{itemize}
\tightlist
\item \textbf{WOM:} Physical irreversibility (bits only increase) $\Rightarrow$ coding schemes maximize information per cell
\item \textbf{DOF = 1:} Structural irreversibility (definition is permanent) $\Rightarrow$ derivation schemes minimize independent encodings
\end{itemize}
Wolf~\cite{wolf1984wom} extended WOM capacity results; our realizability theorem (Theorem~\ref{thm:ssot-iff}) characterizes what encoding systems can achieve DOF = 1 under structural constraints.

\textbf{Classical Source Coding.} Shannon~\cite{shannon1948mathematical} established source coding theory for static data. Slepian and Wolf~\cite{slepian1973noiseless} extended to distributed sources with correlated side information, proving that joint encoding of $(X, Y)$ can achieve rate $H(X|Y)$ for $X$ when $Y$ is available at the decoder.

Our provenance observability requirement (Section~\ref{sec:provenance-observability}) is the encoding-system analog: the decoder (verification procedure) has ``side information'' about the derivation structure, enabling verification of DOF = 1 without examining all locations independently.

\textbf{Rate-Distortion Theory.} Cover and Thomas~\cite{cover2006elements} formalize the rate-distortion function $R(D)$: the minimum encoding rate to achieve distortion $D$. Our rate-complexity tradeoff (Theorem~\ref{thm:unbounded-gap}) is analogous: encoding rate (DOF) trades against modification complexity. DOF = 1 achieves $O(1)$ complexity; DOF $> 1$ incurs $\Omega(n)$.

\textbf{Interactive Information Theory.} The BIRS workshop~\cite{birs2012interactive} identified interactive information theory as an emerging area combining source coding, channel coding, and directed information. Ma and Ishwar~\cite{ma2011distributed} showed that interaction can reduce rate for function computation. Xiang~\cite{xiang2013interactive} studied interactive schemes including feedback channels.

Our framework extends this to \emph{storage} rather than communication: encoding systems where the encoding itself is modified over time, requiring coherence maintenance.

\textbf{Minimum Description Length.} Rissanen~\cite{rissanen1978mdl} established MDL: the optimal model minimizes total description length (model + data given model). GrÃ¼nwald~\cite{gruenwald2007mdl} proved uniqueness of MDL-optimal representations.

DOF = 1 is the MDL-optimal encoding for redundant facts: the single source is the model; derived locations have zero marginal description length (fully determined by source). Additional independent encodings add description length without reducing uncertainty---pure overhead. Our Theorem~\ref{thm:dof-optimal} establishes analogous uniqueness for encoding systems under modification constraints.

\subsection{Distributed Systems Consistency}\label{sec:related-distributed}

Our coherence requirement connects to fundamental results in distributed systems.

\textbf{CAP Theorem.} Brewer~\cite{brewer2000cap} conjectured (Gilbert and Lynch~\cite{gilbert2002cap} proved) that distributed systems cannot simultaneously guarantee Consistency, Availability, and Partition tolerance.

Our DOF framework instantiates this tradeoff:
\begin{itemize}
\tightlist
\item \textbf{Consistency} = Coherence (all locations agree)
\item \textbf{Availability} = Locations can be modified independently
\item \textbf{Partition tolerance} = No global synchronization required
\end{itemize}

DOF $> 1$ with independent modification and no coordination is precisely the CAP-impossible regime. DOF = 1 sidesteps CAP by eliminating independent locations---there's only one source, so no partition between sources is possible.

\textbf{FLP Impossibility.} Fischer, Lynch, and Paterson~\cite{flp1985impossibility} proved that deterministic consensus is impossible in asynchronous systems with even one faulty process.

Our resolution impossibility theorem (Theorem~\ref{thm:oracle-arbitrary}) is a \emph{static} analog: given incoherent encodings (DOF $> 1$ with divergent values), no resolution procedure is information-theoretically justified. FLP says consensus cannot be \emph{reached}; we say which value is correct cannot be \emph{determined}.

\textbf{Consensus Algorithms.} Lamport's Paxos~\cite{lamport1998paxos} and Ongaro's Raft~\cite{ongaro2014raft} achieve consistency by coordinating updates across replicas. This is DOF $> 1$ with coordination overhead to maintain coherence.

DOF = 1 eliminates the need for coordination: there's only one source, so consensus is trivial (the source is authoritative). The tradeoff: DOF = 1 has no redundancy for fault tolerance; DOF $> 1$ with consensus has fault tolerance but coordination cost.

\textbf{Formal Connections.} We now state the precise relationships:

\begin{theorem}[DOF Instantiates CAP]\label{thm:dof-cap}
The DOF framework is an instantiation of CAP:
\begin{enumerate}
\tightlist
\item DOF = 1: Achieves Consistency (coherence) by eliminating Partition tolerance (only one source to partition)
\item DOF $> 1$ without coordination: Has Availability and Partition tolerance but not Consistency
\item DOF $> 1$ with consensus: Achieves Consistency by sacrificing Availability (blocking during coordination)
\end{enumerate}
\end{theorem}

\begin{proof}
\textbf{(1)} With DOF = 1, all locations except the source are derived. Derived locations cannot be modified independently---they track the source. There is no ``partition between sources'' because there is only one source. Consistency (coherence) is guaranteed by Theorem~\ref{thm:dof-one-coherence}.

\textbf{(2)} With DOF $> 1$ and no coordination, independent locations can be modified without synchronization (Availability) and without global knowledge of other locations (Partition tolerance). By Theorem~\ref{thm:dof-gt-one-incoherence}, incoherent states are reachable (no Consistency).

\textbf{(3)} Consensus protocols (Paxos, Raft) restore Consistency to DOF $> 1$ systems by blocking updates until agreement is reached. During consensus, locations are not available for independent modification.
\end{proof}

\begin{theorem}[Resolution Impossibility as Static FLP]\label{thm:resolution-flp}
Our resolution impossibility (Theorem~\ref{thm:oracle-arbitrary}) is a static analog of FLP:
\begin{itemize}
\tightlist
\item \textbf{FLP:} In asynchronous systems with failures, no deterministic algorithm can guarantee consensus termination
\item \textbf{This work:} In incoherent encoding systems, no deterministic procedure can identify the correct value
\end{itemize}
The common structure: insufficient information makes correct resolution impossible.
\end{theorem}

\begin{proof}
FLP proves consensus impossibility by constructing adversarial message delays that prevent termination. Our proof (Theorem~\ref{thm:oracle-arbitrary}) is simpler: with $k$ equally-present values and no side information distinguishing them, any selection is arbitrary.

The parallel: FLP shows \emph{which value is agreed upon} cannot be determined (no termination); we show \emph{which value is correct} cannot be determined (no ground truth).

The key insight: both results arise from insufficient information. FLP lacks information about process states; we lack information about authoritative sources.
\end{proof}

\begin{corollary}[DOF = 1 Sidesteps FLP]\label{cor:dof1-flp}
DOF = 1 systems avoid the FLP dilemma: with one independent source, ``consensus'' is trivial (the source is authoritative).
\end{corollary}

\begin{proof}
FLP applies to systems with multiple processes that must agree. With DOF = 1, there are no multiple independent sources to agree---consensus is vacuously achieved. The single source determines all values.
\end{proof}

\subsection{Computational Reflection and Metaprogramming}\label{sec:related-meta}

\textbf{Metaobject Protocols.} Kiczales et al.~\cite{kiczales1991art} established theoretical foundations for MOPs in \textit{The Art of the Metaobject Protocol}. MOPs allow programs to inspect and modify their own structure at runtime.

Our realizability requirements (causal propagation, provenance observability) explain \emph{why} MOP-equipped systems (CLOS, Smalltalk, Python) can achieve DOF = 1: MOPs provide both capabilities. Systems without MOPs cannot achieve DOF = 1 for structural facts.

\textbf{Computational Reflection.} Smith~\cite{smith1984reflection} introduced computational reflection: programs reasoning about themselves. Reflection enables provenance observability (Requirement 2, Section~\ref{sec:provenance-observability}).

\textbf{Generative Complexity.} Heering~\cite{heering2015generative,heering2003software} formalized \emph{generative complexity} as the Kolmogorov complexity of the shortest generator for a program family. DOF = 1 systems achieve minimal generative complexity: the single source is the shortest generator.

Our contribution is the \emph{constructive realization}: specific encoding-system properties (causal propagation, provenance observability) that achieve the theoretical minimum in practice.

\subsection{Software Engineering Principles}\label{sec:related-software}

\textbf{DRY Principle.} Hunt and Thomas~\cite{hunt1999pragmatic} articulated DRY (Don't Repeat Yourself):
\begin{quote}
``Every piece of knowledge must have a single, unambiguous, authoritative representation within a system.''
\end{quote}

Our contribution: formal definition (DOF = 1), information-theoretic foundation, realizability requirements, and machine-checked proofs. Hunt and Thomas provide guidance; we provide a decision procedure.

\textbf{Information Hiding.} Parnas~\cite{parnas1972criteria} established information hiding: modules should hide decisions likely to change. DOF = 1 and information hiding are complementary:
\begin{itemize}
\tightlist
\item Information hiding determines \emph{what} to encapsulate
\item DOF = 1 determines \emph{how} to avoid duplicating what is exposed
\end{itemize}

\textbf{Complexity Metrics.} McCabe~\cite{mccabe1976complexity} introduced cyclomatic complexity (execution complexity). Our DOF metric measures \emph{modification} complexity, orthogonal to execution complexity.

Stevens et al.~\cite{stevens1974structured} introduced coupling and cohesion. High DOF indicates high coupling (many locations must change together) and low cohesion (related information is scattered).

\textbf{Code Duplication.} Fowler~\cite{fowler1999refactoring} identified duplication as a code smell. Roy and Cordy~\cite{roy2007survey} survey clone detection; Juergens et al.~\cite{juergens2009clones} showed clones cause maintenance problems. Our DOF metric formalizes this: DOF $> 1$ is duplication for a fact.

\subsection{Formal Methods}\label{sec:related-formal}

\textbf{Type Theory.} Pierce~\cite{pierce2002types} formalized type systems with machine-checked proofs. Our work applies similar rigor to encoding theory and realizability requirements.

\textbf{Program Semantics.} Winskel~\cite{winskel1993semantics} formalized programming language semantics. Our formalization of DOF = 1 realizability requirements is in the same tradition.

\textbf{Verified Software.} CompCert~\cite{leroy2009compcert} demonstrated that production software can be formally verified. Our Lean 4~\cite{demoura2021lean4} proofs (9,351 lines, 541 theorems, 0 \texttt{sorry}) follow this tradition.

\subsection{Novelty of This Work}\label{sec:novelty}

To our knowledge, this is the first work to:
\begin{enumerate}
\tightlist
\item \textbf{Extend source coding to interactive encoding systems}---systems where encodings can be modified and must remain coherent. This generalizes classical IT (static encoding) to mutable systems.

\item \textbf{Connect multi-version coding to software architecture}---Rashmi et al.'s consistency cost for distributed storage is analogous to our coherence cost for software systems.

\item \textbf{Abstract realizability requirements to IT}---``causal propagation'' and ``provenance observability'' are encoder properties, not PL-specific features. Definition-time hooks and introspection are one instantiation.

\item \textbf{Establish DOF = 1 as capacity-optimal}---The coherence ``capacity'' of encoding systems is achieved at rate 1. This is a tight bound: DOF = 0 fails to encode; DOF $> 1$ cannot guarantee coherence.

\item \textbf{Connect to CAP and FLP}---Our resolution impossibility (Theorem~\ref{thm:oracle-arbitrary}) is a static analog of FLP; DOF = 1 sidesteps CAP by eliminating the partition dimension.

\item \textbf{Provide machine-checked proofs}---All theorems formalized in Lean 4 with 0 \texttt{sorry} placeholders.
\end{enumerate}

\textbf{Information-theoretic contribution:} We extend classical IT to mutable encoding systems with coherence constraints. The rate-complexity tradeoff (DOF vs. modification cost) is analogous to rate-distortion; the realizability requirements (causal propagation, provenance observability) characterize when capacity is achievable.

\textbf{Practical contribution:} The abstract requirements instantiate across domains: programming languages (hooks + introspection), databases (triggers + system catalogs), distributed systems (consensus + provenance tracking). The theory explains observed convergence toward certain architectural patterns.

%==============================================================================
