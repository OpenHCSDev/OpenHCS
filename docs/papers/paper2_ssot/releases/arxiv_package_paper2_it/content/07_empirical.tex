\section{Practical Demonstration}\label{sec:empirical}
%==============================================================================

We demonstrate the theoretical results with concrete before/after examples from OpenHCS~\cite{openhcs2025}, a production bioimage analysis platform. These examples show how Python's definition-time hooks achieve SSOT for structural facts.

\textbf{Methodology:} This case study follows established guidelines for software engineering case studies~\cite{runeson2009guidelines}. We use a single-case embedded design with multiple units of analysis (DOF measurements, code changes, maintenance metrics).

The value of these examples is \emph{qualitative}: they show the pattern, not aggregate statistics. Each example demonstrates a specific SSOT mechanism. Readers can verify the pattern applies to their own codebases.

\subsection{SSOT Patterns}\label{sec:ssot-patterns-practical}

Three patterns recur in SSOT architectures:

\begin{enumerate}
\item \textbf{Contract enforcement via ABC:} Replace scattered \texttt{hasattr()} checks with a single abstract base class. The ABC is the single source; \texttt{isinstance()} checks are derived.

\item \textbf{Automatic registration via \texttt{\_\_init\_subclass\_\_}:} Replace manual registry dictionaries with automatic registration at class definition time. The class definition is the single source; the registry entry is derived.

\item \textbf{Automatic discovery via \texttt{\_\_subclasses\_\_()}:} Replace explicit import lists with runtime enumeration of subclasses. The inheritance relationship is the single source; the plugin list is derived.
\end{enumerate}

\subsection{Detailed Examples}\label{sec:detailed-cases}

We present three examples showing before/after code for each pattern.

\subsubsection{Pattern 1: Contract Enforcement (PR \#44~\cite{openhcsPR44})}

This example is from a publicly verifiable pull request~\cite{openhcsPR44}. The PR eliminated 47 scattered \texttt{hasattr()} checks by introducing ABC contracts, reducing DOF from 47 to 1.

\textbf{The Problem:} The codebase used duck typing to check for optional capabilities:

\begin{verbatim}
# BEFORE: 47 scattered hasattr() checks (DOF = 47)

# In pipeline.py
if hasattr(processor, 'supports_gpu'):
    if processor.supports_gpu():
        use_gpu_path(processor)

# In serializer.py
if hasattr(obj, 'to_dict'):
    return obj.to_dict()

# In validator.py
if hasattr(config, 'validate'):
    config.validate()

# ... 44 more similar checks across 12 files
\end{verbatim}

Each \texttt{hasattr()} check is an independent encoding of the fact ``this type has capability X.'' If a capability is renamed or removed, all 47 checks must be updated.

\textbf{The Solution:} Replace duck typing with ABC contracts:

\begin{verbatim}
# AFTER: 1 ABC definition (DOF = 1)

class GPUCapable(ABC):
    @abstractmethod
    def supports_gpu(self) -> bool: ...

class Serializable(ABC):
    @abstractmethod
    def to_dict(self) -> dict: ...

class Validatable(ABC):
    @abstractmethod
    def validate(self) -> None: ...

# Usage: isinstance() checks are derived from ABC
if isinstance(processor, GPUCapable):
    if processor.supports_gpu():
        use_gpu_path(processor)
\end{verbatim}

The ABC is the single source. The \texttt{isinstance()} check is derived. It queries the ABC's \texttt{\_\_subclasshook\_\_} or MRO, not an independent encoding.

\textbf{DOF Analysis:}
\begin{itemize}
\tightlist
\item Pre-refactoring: 47 independent \texttt{hasattr()} checks
\item Post-refactoring: 1 ABC definition per capability
\item Reduction: 47$\times$
\end{itemize}

\subsubsection{Pattern 2: Automatic Registration}

This pattern applies whenever classes must be registered in a central location.

\textbf{The Problem:} Type converters were registered in a manual dictionary:

\begin{verbatim}
# BEFORE: Manual registry (DOF = n, where n = number of converters)

# In converters.py
class NumpyConverter:
    def convert(self, data): ...

class TorchConverter:
    def convert(self, data): ...

# In registry.py (SEPARATE FILE - independent encoding)
CONVERTERS = {
    'numpy': NumpyConverter,
    'torch': TorchConverter,
    # ... more entries that must be maintained manually
}
\end{verbatim}

Adding a new converter requires: (1) defining the class, (2) adding to the registry. Two independent edits, violating SSOT.

\textbf{The Solution:} Use \texttt{\_\_init\_subclass\_\_} for automatic registration:

\begin{verbatim}
# AFTER: Automatic registration (DOF = 1)

class Converter(ABC):
    _registry = {}

    def __init_subclass__(cls, format=None, **kwargs):
        super().__init_subclass__(**kwargs)
        if format:
            Converter._registry[format] = cls

    @abstractmethod
    def convert(self, data): ...

class NumpyConverter(Converter, format='numpy'):
    def convert(self, data): ...

class TorchConverter(Converter, format='torch'):
    def convert(self, data): ...

# Registry is automatically populated
# Converter._registry == {'numpy': NumpyConverter, 'torch': TorchConverter}
\end{verbatim}

\textbf{DOF Analysis:}
\begin{itemize}
\tightlist
\item Pre-refactoring: $n$ manual registry entries (1 per converter)
\item Post-refactoring: 1 base class with \texttt{\_\_init\_subclass\_\_}
\item The single source is the class definition; the registry entry is derived
\end{itemize}

\subsubsection{Pattern 3: Automatic Discovery}

This pattern applies whenever all subclasses of a type must be enumerated.

\textbf{The Problem:} Plugins were discovered via explicit imports:

\begin{verbatim}
# BEFORE: Explicit plugin list (DOF = n, where n = number of plugins)

# In plugin_loader.py
from plugins import (
    DetectorPlugin,
    SegmenterPlugin,
    FilterPlugin,
    # ... more imports that must be maintained
)

PLUGINS = [
    DetectorPlugin,
    SegmenterPlugin,
    FilterPlugin,
    # ... more entries that must match the imports
]
\end{verbatim}

Adding a plugin requires: (1) creating the plugin file, (2) adding the import, (3) adding to the list. Three edits for one fact, violating SSOT.

\textbf{The Solution:} Use \texttt{\_\_subclasses\_\_()} for automatic discovery:

\begin{verbatim}
# AFTER: Automatic discovery (DOF = 1)

class Plugin(ABC):
    @abstractmethod
    def execute(self, context): ...

# In plugin_loader.py
def discover_plugins():
    return Plugin.__subclasses__()

# Plugins just need to inherit from Plugin
class DetectorPlugin(Plugin):
    def execute(self, context): ...
\end{verbatim}

\textbf{DOF Analysis:}
\begin{itemize}
\tightlist
\item Pre-refactoring: $n$ explicit entries (imports + list)
\item Post-refactoring: 1 base class definition
\item The single source is the inheritance relationship; the plugin list is derived
\end{itemize}

\subsubsection{Pattern 4: Introspection-Driven Code Generation}

This pattern demonstrates why both SSOT requirements (definition-time hooks \emph{and} introspection) are necessary. The code is from \texttt{openhcs/debug/pickle\_to\_python.py}, which converts serialized Python objects to runnable Python scripts.

\textbf{The Problem:} Given a runtime object (dataclass instance, enum value, function with arguments), generate valid Python code that reconstructs it. The generated code must include:

\begin{itemize}
\item Import statements for all referenced types
\item Default values for function parameters
\item Field definitions for dataclasses
\item Module paths for enums
\end{itemize}

\textbf{Without SSOT:} Manual maintenance lists

\begin{verbatim}
# Hypothetical non-introspectable language
IMPORTS = {
    "sklearn.filters": ["gaussian", "sobel"],
    "numpy": ["array"],
    # Must manually update when types change
}

DEFAULT_VALUES = {
    "gaussian": {"sigma": 1.0, "mode": "reflect"},
    # Must manually update when signatures change
}
\end{verbatim}

Every type, every function parameter, every enum. Each requires a manual entry. When a function signature changes, both the function \emph{and} the metadata list must be updated. DOF $>$ 1.

\textbf{With SSOT (Python):} Derive everything from introspection

\begin{verbatim}
def collect_imports_from_data(data_obj):
    """Traverse structure, derive imports from metadata."""
    if isinstance(obj, Enum):
        # Enum definition is single source
        module = obj.__class__.__module__
        name = obj.__class__.__name__
        enum_imports[module].add(name)

    elif is_dataclass(obj):
        # Dataclass definition is single source
        function_imports[obj.__class__.__module__].add(
            obj.__class__.__name__)
        # Fields are derived via introspection
        for f in fields(obj):
            register_imports(getattr(obj, f.name))

def generate_dataclass_repr(instance):
    """Generate constructor call from field metadata."""
    for field in dataclasses.fields(instance):
        current_value = getattr(instance, field.name)
        # Field name, type, default all come from definition
        lines.append(f"{field.name}={repr(current_value)}")
\end{verbatim}

\textbf{The Key Insight:} The class definition at definition-time establishes facts:
\begin{itemize}
\item \texttt{@dataclass} decorator $\to$ \texttt{dataclasses.fields()} returns field metadata
\item \texttt{Enum} definition $\to$ \texttt{\_\_module\_\_}, \texttt{\_\_name\_\_} attributes exist
\item Function signature $\to$ \texttt{inspect.signature()} returns parameter defaults
\end{itemize}

Each manual metadata entry is replaced by an introspection query. The definition is the single source; the generated code is derived.

\textbf{Why This Requires Both SSOT Properties:}

\begin{enumerate}
\item \textbf{Definition-time hooks:} The \texttt{@dataclass} decorator executes at class definition time, storing field metadata that didn't exist before. Without this hook, \texttt{fields()} would have nothing to query.

\item \textbf{Introspection:} The \texttt{fields()}, \texttt{\_\_module\_\_}, \texttt{inspect.signature()} APIs query the stored metadata. Without introspection, the metadata would exist but be inaccessible.
\end{enumerate}

\textbf{Impossibility in Non-SSOT Languages:}

\begin{itemize}
\item \textbf{Go:} No decorator hooks, no field introspection. Would require external code generation (separate tool maintaining parallel metadata).

\item \textbf{Rust:} Procedural macros can inspect at compile-time but metadata is erased at runtime. Cannot query field names from a runtime struct instance.

\item \textbf{Java:} Reflection provides introspection but no mechanism to store arbitrary metadata at definition-time without annotations (which themselves require manual specification).
\end{itemize}

The pattern is simple: traverse an object graph, query definition-time metadata via introspection, emit Python code. But this simplicity \emph{depends} on both SSOT requirements. Remove either, and the pattern breaks.

\subsection{Summary}\label{sec:practical-summary}

These four patterns (contract enforcement, automatic registration, automatic discovery, and introspection-driven generation) demonstrate how Python's definition-time hooks achieve SSOT for structural facts:

\begin{itemize}
\item \textbf{PR \#44 is verifiable:} The 47 $\to$ 1 reduction can be confirmed by inspecting the public pull request.

\item \textbf{The patterns are general:} Each pattern applies whenever the corresponding structural relationship exists (capability checking, type registration, subclass enumeration, code generation from metadata).

\item \textbf{The mechanism is the same:} In all cases, the class definition becomes the single source, and secondary representations (registry entries, plugin lists, capability checks, generated code) become derived via Python's definition-time hooks and introspection.
\end{itemize}

The theoretical prediction (that SSOT requires definition-time hooks and introspection) is confirmed by these examples. The patterns shown here are instances of the general mechanism proved in Section~\ref{sec:requirements}.

%==============================================================================
