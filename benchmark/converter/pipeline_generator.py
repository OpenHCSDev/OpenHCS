"""
PipelineGenerator - Generate complete runnable OpenHCS pipelines.

DETERMINISTIC ONLY:
Uses pre-absorbed cellprofiler_library. No LLM fallback.
Fails loudly if modules are missing from the absorbed library.

Takes parsed .cppipe modules and generates a complete pipeline file with:
- All imports
- Function references from absorbed library
- FunctionStep wrappers with correct variable_components (from LLM-inferred category)
- Pipeline configuration
"""

import json
import logging
import re
import inspect
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Any

from .parser import ModuleBlock
from .settings_binder import SettingsBinder

logger = logging.getLogger(__name__)


@dataclass
class GeneratedPipeline:
    """Complete generated OpenHCS pipeline."""
    
    name: str
    code: str
    source_cppipe: str
    converted_modules: List[str]
    failed_modules: List[str]
    
    def save(self, output_path: Path) -> None:
        """Save pipeline to file."""
        output_path.write_text(self.code)
        logger.info(f"Saved pipeline to {output_path}")


class PipelineGenerator:
    """
    Generate complete OpenHCS pipeline from converted functions.

    TWO MODES:
    1. Registry-based: Uses pre-absorbed cellprofiler_library (instant, no LLM)
    2. LLM-based: Inline function definitions (fallback for unabsorbed modules)

    Creates a runnable pipeline file with:
    1. Standard imports (+ registry imports if using absorbed library)
    2. Converted function definitions (only for non-registry functions)
    3. FunctionStep wrappers for each function
    4. pipeline_steps list
    """

    # Standard imports for generated pipelines
    IMPORTS_BASE = '''"""
OpenHCS Pipeline - Converted from CellProfiler
Source: {source_file}

Auto-generated by CellProfiler → OpenHCS converter.
"""

import numpy as np
from typing import Tuple, List, Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum

# OpenHCS imports
from openhcs.core.steps.function_step import FunctionStep
from openhcs.core.config import LazyProcessingConfig
from openhcs.constants.constants import VariableComponents, GroupBy
from openhcs.core.memory.decorators import numpy
from openhcs.processing.backends.lib_registry.unified_registry import ProcessingContract
from openhcs.core.pipeline.function_contracts import special_outputs
from openhcs.processing.materialization import csv_materializer

'''

    def __init__(self, library_root: Optional[Path] = None):
        """
        Initialize generator.

        Args:
            library_root: Path to absorbed cellprofiler_library
        """
        self.library_root = library_root or Path(__file__).parent.parent / "cellprofiler_library"
        self.settings_binder = SettingsBinder()
        self._registry = self._load_registry()

    def _load_registry(self) -> Dict[str, dict]:
        """Load full module metadata from absorbed library."""
        contracts_file = self.library_root / "contracts.json"
        if not contracts_file.exists():
            raise FileNotFoundError(
                f"No absorbed library found at {contracts_file}. "
                "Run 'python -m benchmark.converter.absorb' first."
            )

        try:
            data = json.loads(contracts_file.read_text())
            # Store full metadata, not just function name
            registry = {
                module_name: {
                    "function_name": info["function_name"],
                    "contract": info.get("contract", "pure_2d"),
                    "category": info.get("category", "image_operation"),
                    "confidence": info.get("confidence", 0.5),
                }
                for module_name, info in data.items()
                if info.get("validated", False)
            }
            logger.info(f"Loaded {len(registry)} absorbed functions from registry")
            return registry
        except Exception as e:
            raise RuntimeError(f"Failed to load registry: {e}")

    def has_module(self, module_name: str) -> bool:
        """Check if module exists in absorbed library."""
        return module_name in self._registry
    
    def generate_from_registry(
        self,
        pipeline_name: str,
        source_cppipe: Path,
        modules: List[ModuleBlock],
        skipped_modules: Optional[List[ModuleBlock]] = None,
    ) -> GeneratedPipeline:
        """
        Generate pipeline using absorbed library (instant, no LLM).

        Args:
            pipeline_name: Name for the generated pipeline
            source_cppipe: Path to source .cppipe file
            modules: ModuleBlocks from .cppipe parser (processing modules only)
            skipped_modules: Infrastructure modules that were skipped

        Returns:
            GeneratedPipeline using registry functions
        """
        skipped_modules = skipped_modules or []

        # Partition modules into registry-available and missing
        registry_modules = []
        missing_modules = []

        for module in modules:
            if module.name in self._registry:
                registry_modules.append(module)
            else:
                missing_modules.append(module)
                logger.warning(f"Module {module.name} not in absorbed library")

        # Build imports
        imports = self.IMPORTS_BASE.format(source_file=source_cppipe.name)

        # Add note about skipped infrastructure modules
        if skipped_modules:
            skip_note = "\n# Skipped infrastructure modules (handled by OpenHCS):\n"
            for module in skipped_modules:
                if module.name == "LoadData":
                    skip_note += "#   - LoadData -> handled by plate_path + openhcs_metadata.json\n"
                elif module.name == "ExportToSpreadsheet":
                    skip_note += "#   - ExportToSpreadsheet -> handled by @special_outputs(csv_materializer(...))\n"
                else:
                    skip_note += f"#   - {module.name}\n"
            imports += skip_note + "\n"

        # Fail-loud if any modules are missing (no LLM fallback)
        if missing_modules:
            raise ValueError(
                f"Missing {len(missing_modules)} modules from absorbed library: "
                f"{[m.name for m in missing_modules]}. "
                "Re-run absorption with --force to regenerate."
            )

        # Add registry imports for available modules
        if registry_modules:
            func_imports = [
                "# Absorbed CellProfiler functions",
                "from benchmark.cellprofiler_library import ("
            ]
            for module in registry_modules:
                func_name = self._registry[module.name]["function_name"]
                func_imports.append(f"    {func_name},")
            func_imports.append(")")
            imports += "\n".join(func_imports) + "\n\n"

        # Generate steps with bound settings
        steps = self._generate_steps_from_registry(registry_modules)

        # Combine
        code = imports + steps

        return GeneratedPipeline(
            name=pipeline_name,
            code=code,
            source_cppipe=str(source_cppipe),
            converted_modules=[m.name for m in registry_modules],
            failed_modules=[m.name for m in missing_modules],
        )

    # Category → variable_components mapping
    CATEGORY_TO_VARIABLE_COMPONENTS = {
        "image_operation": "VariableComponents.SITE",
        "z_projection": "VariableComponents.Z_INDEX",
        "channel_operation": "VariableComponents.CHANNEL",
    }

    def _generate_steps_from_registry(self, modules: List[ModuleBlock]) -> str:
        """Generate pipeline_steps using registry functions with bound settings."""
        lines = [
            "# Pipeline Steps",
            "# Settings from .cppipe are bound as default parameters",
            "# variable_components derived from LLM-inferred category",
            "pipeline_steps = [",
        ]

        for module in modules:
            meta = self._registry[module.name]
            func_name = meta["function_name"]
            category = meta.get("category", "image_operation")
            step_name = module.name

            # Map category to variable_components
            var_comp = self.CATEGORY_TO_VARIABLE_COMPONENTS.get(
                category, "VariableComponents.SITE"
            )

            # Bind settings to kwargs
            kwargs = self.settings_binder.bind(module.settings)

            # Parse parameter mapping from function docstring
            param_mapping = self._parse_parameter_mapping(func_name)

            # Translate kwargs using mapping
            translated_kwargs = {}
            unmapped_kwargs = {}

            for cp_setting, value in kwargs.items():
                if cp_setting in param_mapping:
                    py_param = param_mapping[cp_setting]

                    # Skip pipeline-handled settings
                    if py_param is None:
                        continue

                    # Handle list of parameters (e.g., min/max from tuple)
                    if isinstance(py_param, list):
                        if isinstance(value, tuple) and len(value) == len(py_param):
                            for i, param_name in enumerate(py_param):
                                translated_kwargs[param_name] = value[i]
                        else:
                            # Can't split - use first param
                            translated_kwargs[py_param[0]] = value
                    else:
                        translated_kwargs[py_param] = value
                else:
                    # No mapping found - keep as comment
                    unmapped_kwargs[cp_setting] = value

            # Build func parameter - either just the function or (function, kwargs_dict)
            if translated_kwargs:
                # Format kwargs dict
                kwargs_lines = ["{"]
                for k, v in translated_kwargs.items():
                    kwargs_lines.append(f"            {repr(k)}: {repr(v)},")
                kwargs_lines.append("        }")
                kwargs_str = "\n".join(kwargs_lines)

                lines.append(f"    FunctionStep(")
                lines.append(f"        func=({func_name}, {kwargs_str}),")
            else:
                lines.append(f"    FunctionStep(")
                lines.append(f"        func={func_name},")

            lines.append(f'        name="{step_name}",')
            lines.append(f"        processing_config=LazyProcessingConfig(")
            lines.append(f"            variable_components=[{var_comp}]")
            lines.append(f"        ),")

            # Add unmapped settings as comments (for debugging)
            if unmapped_kwargs:
                lines.append(f"        # Unmapped settings:")
                for k, v in list(unmapped_kwargs.items())[:3]:
                    lines.append(f"        # {k}={repr(v)}")

            lines.append(f"    ),")

        lines.append("]")
        return "\n".join(lines)

    def _module_to_function_name(self, module_name: str) -> str:
        """Convert module name to function name (snake_case)."""
        # IdentifyPrimaryObjects -> identify_primary_objects
        name = re.sub(r'([A-Z])', r'_\1', module_name).lower().lstrip('_')
        return name

    def _normalize_setting_name(self, setting_name: str) -> str:
        """
        Normalize CellProfiler setting name to match SettingsBinder output.

        This EXACTLY matches the normalization done by SettingsBinder._normalize_name():
        1. Remove parenthetical content: "(Min,Max)" -> ""
        2. Remove question marks
        3. Replace special chars with spaces
        4. Convert to lowercase and split on whitespace
        5. Join with underscores

        Example:
            "Select the input image" -> "select_the_input_image"
            "Typical diameter of objects, in pixel units (Min,Max)" -> "typical_diameter_of_objects_in_pixel_units"
        """
        # Remove parenthetical content (CRITICAL - must match SettingsBinder)
        name = re.sub(r'\([^)]*\)', '', setting_name)

        # Remove question marks
        name = name.replace('?', '')

        # Replace special chars with spaces
        name = re.sub(r'[^\w\s]', ' ', name)

        # Convert to lowercase and split
        words = name.lower().split()

        # Join with underscores
        return '_'.join(words)

    def _parse_parameter_mapping(self, func_name: str) -> Dict[str, Any]:
        """
        Parse parameter mapping from function docstring.

        Returns dict mapping CellProfiler setting names to Python parameter names.
        Example: {'Typical diameter...' -> ['min_diameter', 'max_diameter']}
        """
        try:
            # Read the file directly (no imports needed - mappings are in the .py files)
            module_name = func_name.replace('_', '')
            func_file = Path(__file__).parent.parent / "cellprofiler_library" / "functions" / f"{module_name}.py"

            if not func_file.exists():
                return {}

            # Read file content
            content = func_file.read_text()

            # Find the parameter mapping section (anywhere in the file)
            mapping = {}
            in_mapping_section = False

            for line in content.split('\n'):
                stripped = line.strip()

                if 'CellProfiler Parameter Mapping:' in stripped:
                    in_mapping_section = True
                    continue

                if in_mapping_section:
                    # Stop at empty line, next section, or another mapping block
                    if not stripped:
                        # Empty line - might be end of section
                        continue
                    if (stripped.startswith('Args:') or
                        stripped.startswith('Returns:') or
                        stripped.startswith('Identify') or
                        stripped.startswith('Measure') or
                        stripped.startswith('"""') or
                        stripped.startswith('from ') or
                        stripped.startswith('import ')):
                        # Reached end of mapping section
                        if mapping:  # Only break if we've collected some mappings
                            break
                        continue

                    # Skip header line
                    if 'CellProfiler setting' in stripped and 'Python parameter' in stripped:
                        continue

                    # Parse mapping line: 'Setting Name' -> param_name
                    # or 'Setting Name' -> [param1, param2]
                    # or 'Setting Name' -> (pipeline-handled)
                    if '->' in stripped:
                        parts = stripped.split('->', 1)
                        if len(parts) == 2:
                            cp_setting = parts[0].strip().strip("'\"")
                            py_param = parts[1].strip()

                            # Normalize the CellProfiler setting name to match SettingsBinder output
                            # "Select the input image" -> "select_the_input_image"
                            # "Typical diameter (Min,Max)" -> "typical_diameter_of_objects_in_pixel_units"
                            normalized_key = self._normalize_setting_name(cp_setting)

                            # Handle (pipeline-handled) or null
                            if 'pipeline-handled' in py_param or py_param == 'null':
                                mapping[normalized_key] = None
                            # Handle list [param1, param2]
                            elif py_param.startswith('[') and py_param.endswith(']'):
                                params = py_param[1:-1].split(',')
                                mapping[normalized_key] = [p.strip() for p in params]
                            # Handle single parameter
                            else:
                                mapping[normalized_key] = py_param

            return mapping

        except Exception as e:
            logger.warning(f"Could not parse parameter mapping for {func_name}: {e}")
            return {}

