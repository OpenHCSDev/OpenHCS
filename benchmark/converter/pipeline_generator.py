"""
PipelineGenerator - Generate complete runnable OpenHCS pipelines.

DETERMINISTIC ONLY:
Uses pre-absorbed cellprofiler_library. No LLM fallback.
Fails loudly if modules are missing from the absorbed library.

Takes parsed .cppipe modules and generates a complete pipeline file with:
- All imports
- Function references from absorbed library
- FunctionStep wrappers with correct variable_components (from LLM-inferred category)
- Pipeline configuration
"""

import json
import logging
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional

from .parser import ModuleBlock
from .settings_binder import SettingsBinder

logger = logging.getLogger(__name__)


@dataclass
class GeneratedPipeline:
    """Complete generated OpenHCS pipeline."""
    
    name: str
    code: str
    source_cppipe: str
    converted_modules: List[str]
    failed_modules: List[str]
    
    def save(self, output_path: Path) -> None:
        """Save pipeline to file."""
        output_path.write_text(self.code)
        logger.info(f"Saved pipeline to {output_path}")


class PipelineGenerator:
    """
    Generate complete OpenHCS pipeline from converted functions.

    TWO MODES:
    1. Registry-based: Uses pre-absorbed cellprofiler_library (instant, no LLM)
    2. LLM-based: Inline function definitions (fallback for unabsorbed modules)

    Creates a runnable pipeline file with:
    1. Standard imports (+ registry imports if using absorbed library)
    2. Converted function definitions (only for non-registry functions)
    3. FunctionStep wrappers for each function
    4. pipeline_steps list
    """

    # Standard imports for generated pipelines
    IMPORTS_BASE = '''"""
OpenHCS Pipeline - Converted from CellProfiler
Source: {source_file}

Auto-generated by CellProfiler → OpenHCS converter.
"""

import numpy as np
from typing import Tuple, List, Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum

# OpenHCS imports
from openhcs.core.steps.function_step import FunctionStep
from openhcs.core.config import LazyProcessingConfig
from openhcs.constants.constants import VariableComponents, GroupBy
from openhcs.core.memory.decorators import numpy
from openhcs.processing.backends.lib_registry.unified_registry import ProcessingContract
from openhcs.core.pipeline.function_contracts import special_outputs
from openhcs.processing.materialization import csv_materializer

'''

    def __init__(self, library_root: Optional[Path] = None):
        """
        Initialize generator.

        Args:
            library_root: Path to absorbed cellprofiler_library
        """
        self.library_root = library_root or Path(__file__).parent.parent / "cellprofiler_library"
        self.settings_binder = SettingsBinder()
        self._registry = self._load_registry()

    def _load_registry(self) -> Dict[str, dict]:
        """Load full module metadata from absorbed library."""
        contracts_file = self.library_root / "contracts.json"
        if not contracts_file.exists():
            raise FileNotFoundError(
                f"No absorbed library found at {contracts_file}. "
                "Run 'python -m benchmark.converter.absorb' first."
            )

        try:
            data = json.loads(contracts_file.read_text())
            # Store full metadata, not just function name
            registry = {
                module_name: {
                    "function_name": info["function_name"],
                    "contract": info.get("contract", "pure_2d"),
                    "category": info.get("category", "image_operation"),
                    "confidence": info.get("confidence", 0.5),
                }
                for module_name, info in data.items()
                if info.get("validated", False)
            }
            logger.info(f"Loaded {len(registry)} absorbed functions from registry")
            return registry
        except Exception as e:
            raise RuntimeError(f"Failed to load registry: {e}")

    def has_module(self, module_name: str) -> bool:
        """Check if module exists in absorbed library."""
        return module_name in self._registry
    
    def generate_from_registry(
        self,
        pipeline_name: str,
        source_cppipe: Path,
        modules: List[ModuleBlock],
        skipped_modules: Optional[List[ModuleBlock]] = None,
    ) -> GeneratedPipeline:
        """
        Generate pipeline using absorbed library (instant, no LLM).

        Args:
            pipeline_name: Name for the generated pipeline
            source_cppipe: Path to source .cppipe file
            modules: ModuleBlocks from .cppipe parser (processing modules only)
            skipped_modules: Infrastructure modules that were skipped

        Returns:
            GeneratedPipeline using registry functions
        """
        skipped_modules = skipped_modules or []

        # Partition modules into registry-available and missing
        registry_modules = []
        missing_modules = []

        for module in modules:
            if module.name in self._registry:
                registry_modules.append(module)
            else:
                missing_modules.append(module)
                logger.warning(f"Module {module.name} not in absorbed library")

        # Build imports
        imports = self.IMPORTS_BASE.format(source_file=source_cppipe.name)

        # Add note about skipped infrastructure modules
        if skipped_modules:
            skip_note = "\n# Skipped infrastructure modules (handled by OpenHCS):\n"
            for module in skipped_modules:
                if module.name == "LoadData":
                    skip_note += "#   - LoadData → handled by plate_path + openhcs_metadata.json\n"
                elif module.name == "ExportToSpreadsheet":
                    skip_note += "#   - ExportToSpreadsheet → handled by @special_outputs(csv_materializer(...))\n"
                else:
                    skip_note += f"#   - {module.name}\n"
            imports += skip_note + "\n"

        # Fail-loud if any modules are missing (no LLM fallback)
        if missing_modules:
            raise ValueError(
                f"Missing {len(missing_modules)} modules from absorbed library: "
                f"{[m.name for m in missing_modules]}. "
                "Re-run absorption with --force to regenerate."
            )

        # Add registry imports for available modules
        if registry_modules:
            func_imports = [
                "# Absorbed CellProfiler functions",
                "from benchmark.cellprofiler_library import ("
            ]
            for module in registry_modules:
                func_name = self._registry[module.name]["function_name"]
                func_imports.append(f"    {func_name},")
            func_imports.append(")")
            imports += "\n".join(func_imports) + "\n\n"

        # Generate steps with bound settings
        steps = self._generate_steps_from_registry(registry_modules)

        # Combine
        code = imports + steps

        return GeneratedPipeline(
            name=pipeline_name,
            code=code,
            source_cppipe=str(source_cppipe),
            converted_modules=[m.name for m in registry_modules],
            failed_modules=[m.name for m in missing_modules],
        )

    # Category → variable_components mapping
    CATEGORY_TO_VARIABLE_COMPONENTS = {
        "image_operation": "VariableComponents.SITE",
        "z_projection": "VariableComponents.Z_INDEX",
        "channel_operation": "VariableComponents.CHANNEL",
    }

    def _generate_steps_from_registry(self, modules: List[ModuleBlock]) -> str:
        """Generate pipeline_steps using registry functions with bound settings."""
        lines = [
            "# Pipeline Steps",
            "# Settings from .cppipe are bound as default parameters",
            "# variable_components derived from LLM-inferred category",
            "pipeline_steps = [",
        ]

        for module in modules:
            meta = self._registry[module.name]
            func_name = meta["function_name"]
            category = meta.get("category", "image_operation")
            step_name = module.name

            # Map category to variable_components
            var_comp = self.CATEGORY_TO_VARIABLE_COMPONENTS.get(
                category, "VariableComponents.SITE"
            )

            # Bind settings to kwargs
            kwargs = self.settings_binder.bind(module.settings)

            lines.append(f"    FunctionStep(")
            lines.append(f"        func={func_name},")
            lines.append(f'        name="{step_name}",')
            lines.append(f"        processing_config=LazyProcessingConfig(")
            lines.append(f"            variable_components=[{var_comp}]")
            lines.append(f"        ),")

            # Add bound settings as step kwargs if any
            if kwargs:
                lines.append(f"        # Settings from .cppipe:")
                for k, v in list(kwargs.items())[:5]:  # Limit for readability
                    lines.append(f"        # {k}={repr(v)}")

            lines.append(f"    ),")

        lines.append("]")
        return "\n".join(lines)

    def _module_to_function_name(self, module_name: str) -> str:
        """Convert module name to function name (snake_case)."""
        # IdentifyPrimaryObjects -> identify_primary_objects
        import re
        name = re.sub(r'([A-Z])', r'_\1', module_name).lower().lstrip('_')
        return name

