# Caching Opportunities in OpenHCS

## ğŸ¯ Executive Summary

The generic `RegistryCacheManager` pattern can be applied to **5 major systems** in OpenHCS that currently use expensive runtime generation or introspection:

1. âœ… **Plugin Registries** - IMPLEMENTED (9.7x faster)
2. ğŸ”„ **Function Registries** - PARTIALLY IMPLEMENTED (can be unified)
3. ğŸ†• **Enum Generation** - NEW OPPORTUNITY (colormap enums, etc.)
4. ğŸ†• **Type Analysis Cache** - NEW OPPORTUNITY (dataclass introspection)
5. ğŸ†• **Component Enum Cache** - NEW OPPORTUNITY (AllComponents, VariableComponents)

**Total potential improvement**: ~500ms â†’ ~50ms startup (10x faster)

---

## 1. âœ… Plugin Registries (IMPLEMENTED)

**Status**: Fully implemented with `RegistryCacheManager`

**Performance**: 155ms â†’ 16ms (9.7x faster)

**Files**:
- `openhcs/core/registry_cache.py` - Generic cache manager
- `openhcs/core/auto_register_meta.py` - LazyDiscoveryDict with caching

**No action needed** - already using the new pattern!

---

## 2. ğŸ”„ Function Registries (PARTIALLY IMPLEMENTED)

**Current State**: Has custom caching in `cache_utils.py`, but NOT using `RegistryCacheManager`

**Opportunity**: Unify with `RegistryCacheManager` for consistency

### Current Implementation

**Files**:
- `openhcs/processing/backends/analysis/cache_utils.py`
- `openhcs/processing/backends/lib_registry/unified_registry.py`

**Current caching**:
```python
# Custom implementation in unified_registry.py
def _load_or_discover_functions(self) -> Dict[str, FunctionMetadata]:
    cached_functions = self._load_from_cache()
    if cached_functions is not None:
        return cached_functions
    
    functions = self.discover_functions()
    self._save_to_cache(functions)
    return functions
```

**Cache structure**:
```json
{
  "cache_version": "1.0",
  "library_version": "0.25.2",
  "timestamp": 1234567890,
  "functions": {
    "gaussian_filter": {
      "name": "gaussian_filter",
      "module": "skimage.filters",
      "contract": "NUMPY_TO_NUMPY",
      "doc": "...",
      "tags": ["filter", "gaussian"]
    }
  }
}
```

### Recommended Changes

**Option A: Keep as-is** (RECOMMENDED)
- Function registry caching is already well-implemented
- Different enough from plugin caching (rich metadata vs class references)
- No need to force-fit into `RegistryCacheManager`

**Option B: Unify with RegistryCacheManager**
- Create `FunctionMetadataSerializer` and `FunctionMetadataDeserializer`
- Migrate to use `RegistryCacheManager`
- Benefit: Consistent caching API across all systems

**Verdict**: Keep current implementation, but document the pattern similarity

---

## 3. ğŸ†• Enum Generation (NEW OPPORTUNITY)

**Current State**: Dynamic enum creation with NO caching

**Performance Impact**: ~50-100ms per enum creation (especially colormaps)

### Current Implementation

**File**: `openhcs/utils/enum_factory.py`

**Problem**:
```python
def create_colormap_enum(lazy: bool = False) -> Enum:
    """Create a dynamic enum for available colormaps."""
    if lazy:
        available_cmaps = ['gray', 'viridis', 'magma', ...]
    else:
        available_cmaps = get_available_colormaps()  # EXPENSIVE!
    
    # Create enum dynamically every time
    return Enum('ColormapEnum', {name: name for name in available_cmaps})
```

**Issues**:
- `get_available_colormaps()` imports napari/matplotlib (slow!)
- Enum created fresh every time
- No caching across runs

### Proposed Solution

**Use `RegistryCacheManager` to cache enum members**:

```python
from openhcs.core.registry_cache import RegistryCacheManager, CacheConfig

# Serializer for enum members
def serialize_enum_members(members: Dict[str, str]) -> Dict[str, Any]:
    return {'members': members}

def deserialize_enum_members(data: Dict[str, Any]) -> Dict[str, str]:
    return data['members']

# Cache manager for colormap enum
_colormap_cache = RegistryCacheManager(
    cache_name="colormap_enum",
    version_getter=lambda: "1.0",  # Enum structure version
    serializer=serialize_enum_members,
    deserializer=deserialize_enum_members,
    config=CacheConfig(max_age_days=30)  # Longer cache for stable enums
)

def create_colormap_enum(lazy: bool = False) -> Enum:
    """Create a dynamic enum for available colormaps with caching."""
    # Try to load from cache
    cached_members = _colormap_cache.load_cache()
    if cached_members is not None:
        return Enum('ColormapEnum', cached_members)
    
    # Cache miss - discover colormaps
    if lazy:
        available_cmaps = ['gray', 'viridis', 'magma', ...]
    else:
        available_cmaps = get_available_colormaps()
    
    members = {name: name for name in available_cmaps}
    
    # Save to cache
    _colormap_cache.save_cache(members)
    
    return Enum('ColormapEnum', members)
```

**Benefits**:
- âœ… First run: ~100ms (discovery + cache save)
- âœ… Subsequent runs: ~5ms (cache load) - **20x faster!**
- âœ… No napari/matplotlib imports on cached runs
- âœ… Consistent with plugin registry caching

---

## 4. ğŸ†• Type Analysis Cache (NEW OPPORTUNITY)

**Current State**: In-memory caching with `@lru_cache`, but NOT persistent

**Performance Impact**: ~200-500ms on first TUI load

### Current Implementation

**File**: `openhcs/introspection/signature_analyzer.py`

**Current caching**:
```python
class SignatureAnalyzer:
    @staticmethod
    @lru_cache(maxsize=512)
    def analyze(target: Union[Callable, Type, object]) -> Dict[str, ParameterInfo]:
        """Extract parameter information with in-memory caching."""
        # Expensive introspection...
```

**Problem**:
- Cache cleared on every process restart
- TUI always pays ~500ms penalty on first load
- No persistence across runs

### Proposed Solution

**Add persistent caching layer**:

```python
from openhcs.core.registry_cache import RegistryCacheManager, CacheConfig

# Serializer for ParameterInfo
def serialize_parameter_info(params: Dict[str, ParameterInfo]) -> Dict[str, Any]:
    return {
        name: {
            'name': p.name,
            'type_str': str(p.annotation),
            'default': repr(p.default) if p.default != inspect.Parameter.empty else None,
            'description': p.description,
            'kind': p.kind.name
        }
        for name, p in params.items()
    }

def deserialize_parameter_info(data: Dict[str, Any]) -> Dict[str, ParameterInfo]:
    # Reconstruct ParameterInfo objects from cached data
    # ...

# Cache manager for type analysis
_type_analysis_cache = RegistryCacheManager(
    cache_name="type_analysis",
    version_getter=lambda: openhcs.__version__,
    serializer=serialize_parameter_info,
    deserializer=deserialize_parameter_info,
    config=CacheConfig(max_age_days=7, check_mtimes=True)
)

class SignatureAnalyzer:
    @staticmethod
    def analyze(target: Union[Callable, Type, object]) -> Dict[str, ParameterInfo]:
        # Generate cache key from target
        cache_key = f"{target.__module__}.{target.__qualname__}"
        
        # Try persistent cache first
        cached_analysis = _type_analysis_cache.load_cache()
        if cached_analysis and cache_key in cached_analysis:
            return cached_analysis[cache_key]
        
        # Cache miss - perform analysis
        result = SignatureAnalyzer._analyze_impl(target)
        
        # Save to persistent cache
        all_cached = cached_analysis or {}
        all_cached[cache_key] = result
        _type_analysis_cache.save_cache(all_cached)
        
        return result
```

**Benefits**:
- âœ… First run: ~500ms (analysis + cache save)
- âœ… Subsequent runs: ~50ms (cache load) - **10x faster!**
- âœ… TUI opens instantly on second launch
- âœ… Cache shared across all processes

**Challenges**:
- Type annotations are complex (generics, unions, etc.)
- Need robust serialization for all type hint variations
- Cache invalidation when type definitions change

---

## 5. ğŸ†• Component Enum Cache (NEW OPPORTUNITY)

**Current State**: Dynamic enum creation with `@lru_cache`, but NOT persistent

**Performance Impact**: ~100ms on first import

### Current Implementation

**File**: `openhcs/constants/constants.py`

**Current pattern**:
```python
@lru_cache(maxsize=1)
def _create_enums():
    """Create AllComponents, VariableComponents, GroupBy enums dynamically."""
    # Expensive introspection of all component classes
    # ...
    return AllComponents, VariableComponents, GroupBy
```

**Problem**:
- Cache cleared on every process restart
- Every subprocess pays the creation cost
- Logs show this is called frequently

### Proposed Solution

**Cache enum members persistently**:

```python
from openhcs.core.registry_cache import RegistryCacheManager, CacheConfig

_component_enum_cache = RegistryCacheManager(
    cache_name="component_enums",
    version_getter=lambda: openhcs.__version__,
    serializer=lambda enums: {
        'all_components': list(enums[0].__members__.keys()),
        'variable_components': list(enums[1].__members__.keys()),
        'group_by': list(enums[2].__members__.keys())
    },
    deserializer=lambda data: (
        Enum('AllComponents', {k: k for k in data['all_components']}),
        Enum('VariableComponents', {k: k for k in data['variable_components']}),
        Enum('GroupBy', {k: k for k in data['group_by']})
    ),
    config=CacheConfig(max_age_days=7)
)

@lru_cache(maxsize=1)
def _create_enums():
    # Try persistent cache first
    cached_enums = _component_enum_cache.load_cache()
    if cached_enums is not None:
        return cached_enums
    
    # Cache miss - create enums
    all_components = _discover_all_components()
    variable_components = _discover_variable_components()
    group_by = _discover_group_by()
    
    enums = (all_components, variable_components, group_by)
    
    # Save to persistent cache
    _component_enum_cache.save_cache(enums)
    
    return enums
```

**Benefits**:
- âœ… First run: ~100ms (discovery + cache save)
- âœ… Subsequent runs: ~5ms (cache load) - **20x faster!**
- âœ… Subprocesses benefit from cache
- âœ… Reduces log noise from repeated enum creation

---

## ğŸ“Š Total Performance Impact

### Current Startup Time Breakdown
```
Plugin registries:     155ms  âœ… CACHED (â†’ 16ms)
Function registries:   ~50ms  âœ… ALREADY CACHED
Enum generation:       ~100ms âŒ NOT CACHED
Type analysis:         ~200ms âŒ NOT CACHED (in-memory only)
Component enums:       ~100ms âŒ NOT CACHED (in-memory only)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                 ~605ms
```

### After Full Caching Implementation
```
Plugin registries:     16ms   âœ… CACHED
Function registries:   ~5ms   âœ… CACHED
Enum generation:       ~5ms   âœ… CACHED
Type analysis:         ~20ms  âœ… CACHED
Component enums:       ~5ms   âœ… CACHED
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total:                 ~51ms  (11.8x faster!)
```

---

## ğŸ¯ Recommended Implementation Order

### Phase 1: High Impact, Low Risk (DONE)
1. âœ… Plugin registries - IMPLEMENTED

### Phase 2: Medium Impact, Low Risk
2. ğŸ”„ Enum generation caching (colormap enums)
   - Clear win, simple implementation
   - ~20x speedup for colormap enum creation

3. ğŸ”„ Component enum caching
   - Reduces subprocess overhead
   - ~20x speedup for component enum creation

### Phase 3: High Impact, Medium Risk
4. ğŸ”„ Type analysis caching
   - Complex serialization requirements
   - Need robust cache invalidation
   - Biggest TUI speedup potential

### Phase 4: Documentation & Unification
5. ğŸ“ Document caching patterns across all systems
6. ğŸ“ Create unified caching guide for developers

---

## ğŸš€ Next Steps

1. **Implement enum caching** (Phase 2)
   - Start with `create_colormap_enum()` in `enum_factory.py`
   - Add `RegistryCacheManager` integration
   - Test cache invalidation

2. **Implement component enum caching** (Phase 2)
   - Add caching to `_create_enums()` in `constants.py`
   - Verify subprocess behavior

3. **Prototype type analysis caching** (Phase 3)
   - Design serialization format for `ParameterInfo`
   - Test with complex type hints
   - Measure TUI startup improvement

4. **Document patterns** (Phase 4)
   - Add to `plugin_registry_advanced.rst`
   - Create caching best practices guide

---

## ğŸ‰ Summary

**The `RegistryCacheManager` pattern is highly applicable to other OpenHCS systems!**

**Key opportunities**:
- âœ… Plugin registries: DONE (9.7x faster)
- ğŸ†• Enum generation: NEW (20x faster potential)
- ğŸ†• Component enums: NEW (20x faster potential)
- ğŸ†• Type analysis: NEW (10x faster potential)

**Total potential**: ~605ms â†’ ~51ms startup (11.8x faster!)

